{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DKTC v4 - TAPT + 대규모 일반대화 데이터 기반\n",
    "\n",
    "## 참고\n",
    "> - https://ratsgo.github.io/embedding/downloaddata.html (한국어 데이터)\n",
    "> - https://github.com/sda96/AIFFEL_3rd_hackerton_TUNiB_DKTC (0.882 달성 전략)\n",
    "> - \"Don't Stop Pretraining\" (Gururangan et al., 2020)\n",
    "\n",
    "## v4 핵심 전략\n",
    "- [v7-1] **TAPT (Task-Adaptive Pre-Training)**: klue/bert-base에 대화 데이터로 MLM 사전학습\n",
    "- [v7-2] **대규모 일반대화 데이터**: korean_safe_conversation(10000) + KOTE(10000) + 기존 소스\n",
    "- [v7-3] **klue/bert-base 모델**: 0.882 달성자와 동일 모델 사용\n",
    "\n",
    "## 유지 전략 (v3~v6)\n",
    "- K-Fold (5F) + R-Drop + Focal Loss\n",
    "- LLRD + FGM + EMA + Label Smoothing\n",
    "- Prior Shift Calibration + Threshold Optimization\n",
    "- Hard Negative 경계 대화 200개\n",
    "- Confidence-based Hard Sample Mining + Dynamic Class Weight\n",
    "- 체크포인트 저장/복구 (런타임 끊김 대비)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NanumGothic 폰트 OK: ['NanumBarunGothic', 'NanumSquareRound', 'NanumGothic', 'NanumMyeongjo', 'NanumBarunGothic', 'NanumSquare', 'NanumSquareRound', 'NanumGothic', 'NanumGothicCoding', 'NanumSquare', 'NanumMyeongjo', 'NanumGothicCoding']\n"
     ]
    }
   ],
   "source": [
    "# 폰트 확인 (이미 설치됨)\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "\n",
    "fonts = [f.name for f in fm.fontManager.ttflist if 'Nanum' in f.name]\n",
    "assert fonts, \"NanumGothic 폰트가 없습니다!\"\n",
    "print(f\"NanumGothic 폰트 OK: {fonts}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "plt.rc('font', family='NanumGothic')\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "plt.figure()\n",
    "plt.title('한국어 테스트')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformers 5.1.0\n",
      "datasets 4.5.0\n",
      "  [OK] smilestyle_dataset.tsv (2,357,401 bytes)\n",
      "  [OK] KakaoData.csv (8,044,757 bytes)\n",
      "  [OK] nsmc_train.txt (14,628,807 bytes)\n",
      "설치 및 다운로드 완료!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# STEP 0-2: 라이브러리 + 데이터 확인 (이미 설치/다운로드 완료)\n",
    "# ============================================================\n",
    "import transformers, datasets, accelerate, sklearn, matplotlib, seaborn, pandas\n",
    "import os\n",
    "\n",
    "print(f\"transformers {transformers.__version__}\")\n",
    "print(f\"datasets {datasets.__version__}\")\n",
    "\n",
    "for f in [\"smilestyle_dataset.tsv\", \"KakaoData.csv\", \"nsmc_train.txt\"]:\n",
    "    assert os.path.exists(f), f\"{f} 파일이 없습니다!\"\n",
    "    print(f\"  [OK] {f} ({os.path.getsize(f):,} bytes)\")\n",
    "\n",
    "print(\"설치 및 다운로드 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [OK] train.csv\n",
      "  [OK] test.csv\n",
      "  [OK] submission.csv\n",
      "\n",
      "작업 폴더: /lambda/nfs/lambda-fs\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "DATA_DIR = '/home/ubuntu/lambda-fs'\n",
    "os.chdir(DATA_DIR)\n",
    "\n",
    "for f in ['train.csv', 'test.csv', 'submission.csv']:\n",
    "    if os.path.exists(f):\n",
    "        print(f\"  [OK] {f}\")\n",
    "    else:\n",
    "        print(f\"  [!!] {f} 없음\")\n",
    "\n",
    "print(f\"\\n작업 폴더: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "GPU: NVIDIA H100 80GB HBM3\n"
     ]
    }
   ],
   "source": [
    "import os, random, re, gc, copy, pickle, time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModel, AutoModelForSequenceClassification,\n",
    "    AutoModelForMaskedLM, DataCollatorForLanguageModeling,\n",
    "    get_linear_schedule_with_warmup\n",
    ")\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
    "from datasets import load_dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.rc('font', family='NanumGothic')\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {DEVICE}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v7 설정 완료\n",
      "베이스 모델: klue/bert-base\n",
      "TAPT: 5ep, lr=2e-05, mlm_prob=0.15\n",
      "Fine-tune: 5ep, lr=2e-05, warmup=0.2\n",
      "체크포인트: /home/ubuntu/lambda-fs/v7_ckpts\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 클래스 매핑 + 하이퍼파라미터 (v7)\n",
    "# ============================================================\n",
    "CLASS_NAMES = ['협박 대화', '갈취 대화', '직장 내 괴롭힘 대화', '기타 괴롭힘 대화', '일반 대화']\n",
    "CLASS2IDX = {name: idx for idx, name in enumerate(CLASS_NAMES)}\n",
    "IDX2CLASS = {idx: name for idx, name in enumerate(CLASS_NAMES)}\n",
    "NUM_CLASSES = 5\n",
    "\n",
    "# [v7-3] klue/bert-base (0.882 달성 모델)\n",
    "BASE_MODEL = 'klue/bert-base'\n",
    "\n",
    "CKPT_DIR = os.path.join(DATA_DIR, 'v7_ckpts')\n",
    "os.makedirs(CKPT_DIR, exist_ok=True)\n",
    "\n",
    "# [v7-1] TAPT 설정\n",
    "TAPT_SAVE_DIR = os.path.join(CKPT_DIR, 'tapt_model')\n",
    "TAPT_EPOCHS = 5\n",
    "TAPT_LR = 2e-5\n",
    "TAPT_BATCH_SIZE = 16\n",
    "TAPT_MLM_PROB = 0.15\n",
    "\n",
    "# Fine-tuning 모델 설정\n",
    "MODEL_CONFIGS = [\n",
    "    {'name': TAPT_SAVE_DIR, 'short': 'KLUE-BERT-TAPT'},\n",
    "]\n",
    "\n",
    "MAX_LEN = 256\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 5\n",
    "LR = 2e-5\n",
    "WEIGHT_DECAY = 0.01\n",
    "WARMUP_RATIO = 0.2  # 0.882 달성자 참고: LR scheduler 0.2\n",
    "MAX_GRAD_NORM = 1.0\n",
    "N_FOLDS = 5\n",
    "PSEUDO_THRESHOLD = 0.95\n",
    "\n",
    "# v4 techniques\n",
    "LLRD_FACTOR = 0.95\n",
    "FGM_EPSILON = 1.0\n",
    "LABEL_SMOOTHING = 0.05\n",
    "EMA_DECAY = 0.999\n",
    "\n",
    "# v5 test distribution estimate\n",
    "EST_TEST_DIST = {0: 39, 1: 23, 2: 21, 3: 39, 4: 378}\n",
    "\n",
    "# v6 quality filter\n",
    "MIN_TEXT_LEN = 15\n",
    "MAX_TEXT_LEN = 500\n",
    "MAX_SPECIAL_RATIO = 0.3\n",
    "\n",
    "print(\"v7 설정 완료\")\n",
    "print(f\"베이스 모델: {BASE_MODEL}\")\n",
    "print(f\"TAPT: {TAPT_EPOCHS}ep, lr={TAPT_LR}, mlm_prob={TAPT_MLM_PROB}\")\n",
    "print(f\"Fine-tune: {EPOCHS}ep, lr={LR}, warmup={WARMUP_RATIO}\")\n",
    "print(f\"체크포인트: {CKPT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 3950개, Test: 500개\n",
      "클래스 분포:\n",
      "class\n",
      "기타 괴롭힘 대화      1094\n",
      "갈취 대화           981\n",
      "직장 내 괴롭힘 대화     979\n",
      "협박 대화           896\n",
      "Name: count, dtype: int64\n",
      "\n",
      ">> '일반 대화' 0개 -> STEP 2에서 대규모 합성 (v7: TAPT용 데이터 포함)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# STEP 1: 데이터 로드\n",
    "# ============================================================\n",
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "submission_df = pd.read_csv('submission.csv')\n",
    "\n",
    "print(f\"Train: {len(train_df)}개, Test: {len(test_df)}개\")\n",
    "print(f\"클래스 분포:\\n{train_df['class'].value_counts()}\")\n",
    "print(f\"\\n>> '일반 대화' 0개 -> STEP 2에서 대규모 합성 (v7: TAPT용 데이터 포함)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "소스 1: SmileStyle (개별 문장)\n",
      "  -> 1200개 수집\n",
      "소스 2: kor_unsmile (개별 문장)\n",
      "  -> 800개 수집\n",
      "소스 3: KakaoChatData (Q+A 쌍)\n",
      "  -> 500개 수집\n",
      "소스 4: NSMC (개별 문장)\n",
      "  -> 500개 수집\n",
      "소스 5: [v7-2] korean_safe_conversation (HuggingFace)\n",
      "  -> 10000개 수집 (총 26979개 중)\n",
      "소스 6: [v7-2] kor_nli 한국어 문장 (HuggingFace)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> 10000개 수집 (총 785404개 중)\n",
      "소스 7: Hard Negative 경계 대화 (v6 유지)\n",
      "  -> 165개 추가 (HN-A:50 HN-B:50 HN-C:50 HN-D:50)\n",
      "\n",
      "총 합성 일반대화 (필터 전): 23165개\n",
      "TAPT용 raw 텍스트: 23165개 (train + normal)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# STEP 2: [v7-2] 대규모 합성 일반대화 + Hard Negative Mining\n",
    "# ============================================================\n",
    "# 참고: 0.882 달성자 전략\n",
    "#   한국어 SNS 5000 + 한국어 대화 5000 + 감성 말뭉치 5000 + 오분류 350\n",
    "# v7: HuggingFace에서 다운로드 가능한 대화 데이터로 대체\n",
    "# ============================================================\n",
    "THREAT_KEYWORDS = [\n",
    "    '죽여', '죽일', '찔러', '칼로', '패줄', '두들겨', '불질러',\n",
    "    '협박', '신고', '경찰', '감옥', '고소', '소송',\n",
    "    '돈 내놔', '송금', '이자', '빚', '갚아',\n",
    "    '해고', '짤리', '사직서', '퇴사', '상사',\n",
    "    '따돌', '왕따', '무시', '괴롭'\n",
    "]\n",
    "\n",
    "def contains_threat(text):\n",
    "    return any(kw in str(text) for kw in THREAT_KEYWORDS)\n",
    "\n",
    "normal_samples = []\n",
    "\n",
    "# ── 소스 1: SmileStyle 개별 문장 (1200개) ──\n",
    "print(\"소스 1: SmileStyle (개별 문장)\")\n",
    "try:\n",
    "    smile_df = pd.read_csv('smilestyle_dataset.tsv', sep='\\t')\n",
    "    target_cols = [c for c in smile_df.columns\n",
    "                   if any(kw in c.lower() for kw in ['informal', 'chat', '반말', 'casual'])]\n",
    "    if not target_cols:\n",
    "        target_cols = smile_df.columns[1:].tolist()\n",
    "    smile_texts = []\n",
    "    for col in target_cols:\n",
    "        smile_texts.extend(smile_df[col].dropna().tolist())\n",
    "    smile_filtered = [str(t).strip() for t in smile_texts\n",
    "                      if not contains_threat(t) and 15 < len(str(t).strip()) < 300]\n",
    "    random.shuffle(smile_filtered)\n",
    "    normal_samples.extend(smile_filtered[:1200])\n",
    "    print(f\"  -> {min(1200, len(smile_filtered))}개 수집\")\n",
    "except Exception as e:\n",
    "    print(f\"  오류: {e}\")\n",
    "\n",
    "# ── 소스 2: kor_unsmile 클린 개별 문장 (800개) ──\n",
    "print(\"소스 2: kor_unsmile (개별 문장)\")\n",
    "try:\n",
    "    unsmile_ds = load_dataset('smilegate-ai/kor_unsmile', split='train')\n",
    "    unsmile_df = unsmile_ds.to_pandas()\n",
    "    if 'clean' in unsmile_df.columns:\n",
    "        clean_texts = unsmile_df[unsmile_df['clean'] == 1]['문장'].tolist()\n",
    "    else:\n",
    "        label_cols = [c for c in unsmile_df.columns if c not in ['문장', 'clean']]\n",
    "        clean_mask = unsmile_df[label_cols].sum(axis=1) == 0\n",
    "        clean_texts = unsmile_df[clean_mask]['문장'].tolist()\n",
    "    clean_filtered = [str(t).strip() for t in clean_texts\n",
    "                      if not contains_threat(t) and 10 < len(str(t).strip()) < 300]\n",
    "    random.shuffle(clean_filtered)\n",
    "    normal_samples.extend(clean_filtered[:800])\n",
    "    print(f\"  -> {min(800, len(clean_filtered))}개 수집\")\n",
    "except Exception as e:\n",
    "    print(f\"  오류: {e}\")\n",
    "\n",
    "# ── 소스 3: KakaoChatData Q+A 쌍 (500개) ──\n",
    "print(\"소스 3: KakaoChatData (Q+A 쌍)\")\n",
    "try:\n",
    "    kakao_df = pd.read_csv('KakaoData.csv')\n",
    "    kakao_pairs = []\n",
    "    for _, row in kakao_df.iterrows():\n",
    "        q = str(row.get('Q', row.iloc[0]))\n",
    "        a = str(row.get('A', row.iloc[1]))\n",
    "        conv = f\"{q} {a}\"\n",
    "        if not contains_threat(conv) and 20 < len(conv) < 400:\n",
    "            kakao_pairs.append(conv)\n",
    "    random.shuffle(kakao_pairs)\n",
    "    normal_samples.extend(kakao_pairs[:500])\n",
    "    print(f\"  -> {min(500, len(kakao_pairs))}개 수집\")\n",
    "except Exception as e:\n",
    "    print(f\"  오류: {e} (건너뜀)\")\n",
    "\n",
    "# ── 소스 4: NSMC 긍정 리뷰 개별 문장 (500개) ──\n",
    "print(\"소스 4: NSMC (개별 문장)\")\n",
    "try:\n",
    "    nsmc_df = pd.read_csv('nsmc_train.txt', sep='\\t')\n",
    "    positive = nsmc_df[nsmc_df['label'] == 1]['document'].dropna().tolist()\n",
    "    pos_filtered = [str(t).strip() for t in positive\n",
    "                    if not contains_threat(t) and 15 < len(str(t).strip()) < 200]\n",
    "    random.shuffle(pos_filtered)\n",
    "    normal_samples.extend(pos_filtered[:500])\n",
    "    print(f\"  -> {min(500, len(pos_filtered))}개 수집\")\n",
    "except Exception as e:\n",
    "    print(f\"  오류: {e}\")\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════\n",
    "# [v7-2 NEW] 소스 5: korean_safe_conversation (10000개)\n",
    "# HuggingFace: jojo0217/korean_safe_conversation\n",
    "# ══════════════════════════════════════════════════════════════\n",
    "print(\"소스 5: [v7-2] korean_safe_conversation (HuggingFace)\")\n",
    "try:\n",
    "    safe_ds = load_dataset('jojo0217/korean_safe_conversation', split='train')\n",
    "    safe_df = safe_ds.to_pandas()\n",
    "    # instruction + output 합쳐서 대화 텍스트 생성\n",
    "    safe_texts = []\n",
    "    for _, row in safe_df.iterrows():\n",
    "        instr = str(row.get('instruction', '')).strip()\n",
    "        outp = str(row.get('output', '')).strip()\n",
    "        conv = f\"{instr} {outp}\".strip()\n",
    "        if conv:\n",
    "            safe_texts.append(conv)\n",
    "    safe_filtered = [t for t in safe_texts\n",
    "                     if not contains_threat(t) and 10 < len(t) < 500]\n",
    "    random.shuffle(safe_filtered)\n",
    "    normal_samples.extend(safe_filtered[:10000])\n",
    "    print(f\"  -> {min(10000, len(safe_filtered))}개 수집 (총 {len(safe_texts)}개 중)\")\n",
    "except Exception as e:\n",
    "    print(f\"  오류: {e}\")\n",
    "    print(\"  -> 건너뜀\")\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════\n",
    "# [v7-2 NEW] 소스 6: KOTE 감성 대화 (3000개)\n",
    "# HuggingFace: searle-j/KOTE\n",
    "# ══════════════════════════════════════════════════════════════\n",
    "print(\"소스 6: [v7-2] kor_nli 한국어 문장 (HuggingFace)\")\n",
    "try:\n",
    "    nli_ds = load_dataset('kor_nli', 'multi_nli', split='train')\n",
    "    nli_df = nli_ds.to_pandas()\n",
    "    nli_texts = nli_df['premise'].dropna().tolist() + nli_df['hypothesis'].dropna().tolist()\n",
    "    nli_filtered = [str(t).strip() for t in nli_texts\n",
    "                    if not contains_threat(t) and 10 < len(str(t).strip()) < 500]\n",
    "    random.shuffle(nli_filtered)\n",
    "    normal_samples.extend(nli_filtered[:10000])\n",
    "    print(f\"  -> {min(10000, len(nli_filtered))}개 수집 (총 {len(nli_texts)}개 중)\")\n",
    "except Exception as e:\n",
    "    print(f\"  오류: {e}\")\n",
    "    print(\"  -> 건너뜀\")\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════\n",
    "# 소스 7: Hard Negative 경계 대화 (200개) - v6에서 유지\n",
    "# ══════════════════════════════════════════════════════════════\n",
    "print(\"소스 7: Hard Negative 경계 대화 (v6 유지)\")\n",
    "hard_negatives = [\n",
    "    # HN-A: 협박 ↔ 정당한 경고/항의/비유적 표현 (50개)\n",
    "    \"야 죽을래 ㅋㅋ 아 진짜 웃겨서 죽겠다 아 배아파 ㅋㅋㅋ 진짜 미쳤어 너 개그맨 해라\",\n",
    "    \"야 너 진짜 맞을래 ㅋㅋ 아 왜 그런 말을 해서 웃기게 만들어 아 진짜 복근 생기겠다\",\n",
    "    \"죽여버린다 ㅋㅋ 아 이 게임 왜 이렇게 어려워 보스 죽여버리고 싶다 진짜\",\n",
    "    \"패버리고 싶다 ㅋㅋ 누구를 이 게임 캐릭터 진짜 짜증나 아 다시 해야지\",\n",
    "    \"칼로 자르고 싶다 뭘 이 케이크 너무 예뻐서 자르기 아까운데 먹어야지\",\n",
    "    \"야 한대 맞을래 ㅋㅋㅋ 농담이야 근데 진짜 왜 그런 얘기를 해 아 웃겨\",\n",
    "    \"미쳤어 진짜 ㅋㅋ 이 짤 봤어 와 진짜 웃겨서 죽는줄 알았어 보내줄까\",\n",
    "    \"너 진짜 미쳤다 ㅋㅋ 이걸 어떻게 생각해내 와 천재 아니야 대단하다 진짜\",\n",
    "    \"야 너 오늘 죽었다 ㅋㅋ 왜 노래방에서 내 노래 뺏어서 불렀잖아 다음엔 내가 먼저\",\n",
    "    \"때려치우고 싶다 뭘 회사 오늘 진짜 힘들었어 야 치킨 먹자 나 오늘 자격 있어\",\n",
    "    \"경찰 부를거야 ㅋㅋ 왜 너 방 너무 더러워서 환경오염 신고해야 할 것 같아\",\n",
    "    \"고소할거야 진짜 ㅋㅋ 왜 네가 나한테 이렇게 맛있는 걸 안 알려줬어 배신자\",\n",
    "    \"불질러버리고 싶다 뭘 이 과제 너무 많아서 다 태워버리고 싶어 ㅋㅋ 농담이야\",\n",
    "    \"찔러버린다 ㅋㅋ 뭘 이 젤리 포크로 찔러서 먹어야 하는데 손으로 먹었어\",\n",
    "    \"감옥에 넣어야 해 ㅋㅋ 누구를 이렇게 늦게 연락하는 너를 지각죄로 가둬야지\",\n",
    "    \"층간소음 계속되면 관리사무소에 정식으로 민원 넣을 거예요 녹음도 다 해뒀습니다\",\n",
    "    \"다시 한번 이런 일 생기면 소비자보호원에 신고하겠습니다 영수증 다 보관하고 있어요\",\n",
    "    \"제가 법률 상담 받아봤는데요 이건 충분히 손해배상 청구 가능하다고 합니다\",\n",
    "    \"경찰에 신고하겠습니다 왜냐면 제 물건을 허락 없이 가져간 건 절도에 해당하거든요\",\n",
    "    \"노동청에 진정서 넣을 수 있다는 거 알고 계시죠 근로기준법 위반이에요\",\n",
    "    \"CCTV 영상 확보했으니까 다음에 또 그러시면 법적으로 대응하겠습니다\",\n",
    "    \"이거 소비자 분쟁 조정위원회에 접수할게요 교환이나 환불 해주셔야 합니다\",\n",
    "    \"변호사 선임해서 내용증명 보내겠습니다 이건 명백한 계약 위반이에요\",\n",
    "    \"학교 폭력 신고 접수하겠습니다 증거 자료 다 모아놨어요 상담 선생님한테 먼저 얘기할게요\",\n",
    "    \"이 문제 공정거래위원회에 제보하겠습니다 허위 광고에 해당하는 것 같아요\",\n",
    "    \"아 죽겠다 진짜 더워서 에어컨 좀 틀어줘 녹을 것 같아\",\n",
    "    \"너 진짜 죽인다 노래 진짜 잘 부른다 가수 해도 되겠다 대박\",\n",
    "    \"아 맞아 죽겠어 ㅋㅋ 이 운동 진짜 힘들다 근데 끝나면 개운하긴 해\",\n",
    "    \"야 폭발할 것 같아 뭐가 시험 스트레스 아 빨리 끝나라\",\n",
    "    \"터질 것 같다 ㅋㅋ 뭐가 밥을 너무 많이 먹었어 배 터지겠어\",\n",
    "    \"미쳐버리겠다 진짜 ㅋㅋ 이 드라마 반전 뭐야 소름 돋았어\",\n",
    "    \"아 진짜 때리고 싶다 ㅋㅋ 누구를 이 알람 시계 매일 아침마다 짜증나\",\n",
    "    \"날려버리고 싶다 뭘 이 다이어트 오늘부터 야식 안 먹는다 진짜로\",\n",
    "    \"밟아버린다 ㅋㅋ 뭘 이 게임 점수 내가 이번에 꼭 이긴다 두고 봐\",\n",
    "    \"찢었다 ㅋㅋ 뭘 시험 만점 받았어 공부한 보람이 있다\",\n",
    "    \"박살 내버렸다 ㅋㅋ 뭘 노래방 점수 100점 나왔어 나 천재인듯\",\n",
    "    \"야 너 오늘 끝장이다 ㅋㅋ 뭐가 볼링 내기에서 졌으니까 밥 사야지\",\n",
    "    \"가만 안 둔다 ㅋㅋ 누구를 내 과자 먹은 사람 당장 자수해\",\n",
    "    \"불태워버리겠다 ㅋㅋ 뭘 이번 축제 무대 내가 완전 불태울거야 기대해\",\n",
    "    \"난리 난다 ㅋㅋ 왜 엄마가 성적표 보면 난리 나겠다 미리 말해야지\",\n",
    "    \"각오해 ㅋㅋ 뭘 다음 게임 내가 연습 많이 했거든 이번엔 진다\",\n",
    "    \"복수한다 ㅋㅋ 어떻게 다음에 술래잡기 할 때 내가 꼭 잡을거야\",\n",
    "    \"잡아먹겠다 ㅋㅋ 누구를 이 떡볶이 너무 맛있어서 다 먹어버리겠어\",\n",
    "    \"쓸어버린다 ㅋㅋ 뭘 대청소 시작이다 방 깨끗하게 만들어야지\",\n",
    "    \"혼내준다 ㅋㅋ 누구를 동생이 내 옷 빌려 입었어 귀엽긴 한데\",\n",
    "\n",
    "    # HN-B: 갈취 ↔ 상호 호혜적 금전 거래/친밀한 요청 (50개)\n",
    "    \"돈 내놔 ㅋㅋ 밥값 네가 쏜다며 아 맞다 내가 쏜다고 했지 ㅋㅋ 어디 갈까\",\n",
    "    \"야 천원만 빌려줘 자판기 커피 마시고 싶은데 지갑을 놓고 왔어 내일 바로 갚을게\",\n",
    "    \"야 그거 빌려줘 뭘 충전기 배터리 없어서 잠깐만 쓸게 고마워\",\n",
    "    \"밥 사라 ㅋㅋ 야 오늘 내 생일인데 당연히 네가 사야지 어디 갈까\",\n",
    "    \"용돈 다 썼어 ㅋㅋ 야 오늘 커피 한잔만 사줘 다음에 내가 쏠게 진짜로\",\n",
    "    \"야 택시비 좀 보태줘 3천원만 있으면 되는데 집에 가야 해 내일 바로 보내줄게\",\n",
    "    \"야 이거 줘 뭐 그 펜 좀 잠깐만 쓸게 아 고마워 나중에 돌려줄게\",\n",
    "    \"돈 있어 얼마 만원만 있으면 되는데 같이 밥 먹으러 가자 내가 부족한 부분 낼게\",\n",
    "    \"야 담배 한 개비 줘봐 아 나 오늘 스트레스 받아서 한 대만 ㅋㅋ 고마워 내일 사줄게\",\n",
    "    \"이거 나 좀 줘 뭐 이 과자 맛있어 보여서 하나만 줘봐 오 진짜 맛있다\",\n",
    "    \"저번에 네가 빌려준 3만원 오늘 갚을게 카카오페이로 보낼까 계좌로 보낼까\",\n",
    "    \"이번 달 회비 만원씩 걷는 거 맞지 내가 총무니까 내일까지 보내줘\",\n",
    "    \"야 우리 생일 선물 5만원 이하로 하기로 했잖아 뭐 사줄까 고민 중이야\",\n",
    "    \"더치페이 하자 각자 먹은 만큼 내는 게 편하지 않아 나 파스타 먹었으니까 만오천원\",\n",
    "    \"축의금 얼마 내야 하지 우리 사이면 5만원 정도면 괜찮을까 같이 내자\",\n",
    "    \"엄마 생신 선물 같이 사자 우리 삼남매 나눠서 내면 한 명당 3만원이면 되지\",\n",
    "    \"동아리 엠티 비용 인당 5만원이래 참가비 내일까지 총무한테 보내면 돼\",\n",
    "    \"이사 도와줘서 고마워 저녁 내가 쏠게 치킨이랑 맥주 어때 골라\",\n",
    "    \"야 내가 빌린 우산 돌려줄게 다음에 만날 때 가져갈게 미안 계속 잊어버렸어\",\n",
    "    \"카풀 기름값 나눠 내자 왕복 2시간이니까 만원씩만 내면 될 것 같아 괜찮지\",\n",
    "    \"야 내기 했으니까 진 사람이 아이스크림 사는 거다 ㅋㅋ 나 딸기맛으로\",\n",
    "    \"선배 커피 사드려야 하는데 같이 돈 모으자 한 명당 천원이면 되잖아\",\n",
    "    \"생일 파티 준비물 내가 케이크 살게 너는 음료수 사와 나중에 정산하자\",\n",
    "    \"야 택배비 반만 내줘 같이 시킨 거잖아 2500원씩 나누면 되지\",\n",
    "    \"정기 모임 식비 만오천원이래 다음 달 거 미리 내도 돼 한꺼번에 정리하게\",\n",
    "    \"중고로 팔 건데 너 혹시 살래 원래 5만원인데 친구니까 3만원에 줄게\",\n",
    "    \"야 내 교통카드 잔액 부족한데 한번만 찍어줘 집 가서 바로 송금할게\",\n",
    "    \"결혼 축하해 축의금은 당일에 직접 줄게 봉투 준비해뒀어\",\n",
    "    \"아르바이트 월급 들어왔다 저번에 빌린 거 오늘 보내줄게 얼마였더라\",\n",
    "    \"회식비 각자 부담이래 메뉴 고르자 예산 인당 2만원 정도면 괜찮겠다\",\n",
    "    \"야 주차비 내가 낼게 네가 운전해줬으니까 이 정도는 내가 내야지\",\n",
    "    \"보증금 돌려받으면 빌린 거 갚을게 이번 달 말에 나온대 조금만 기다려줘\",\n",
    "    \"야 이거 반값 할인이다 같이 사면 배송비 무료래 나눠 갖자\",\n",
    "    \"점심값 내가 카드로 긁었으니까 너 몫 만이천원 보내줘 카카오페이로\",\n",
    "    \"엄마한테 용돈 받으면 갚을게 진짜 미안 이번 달만 좀 도와줘\",\n",
    "    \"여행 경비 미리 걷자 항공권이랑 숙소비 합치면 인당 30만원 정도야\",\n",
    "    \"야 내가 대신 결제했으니까 네 몫 나중에 줘 급한 거 아니니까 천천히\",\n",
    "    \"문화상품권 남는 거 있으면 하나만 줘 게임 아이템 사고 싶은데 부족해\",\n",
    "    \"야 커피 한잔 사줄래 오늘 내가 발표 잘 했거든 축하 의미로 ㅎㅎ\",\n",
    "    \"오늘 간식 내가 쏠게 편의점에서 뭐 먹고 싶어 골라 내가 계산할게\",\n",
    "\n",
    "    # HN-C: 직장괴롭힘 ↔ 엄격하지만 정당한 업무 지시 (50개)\n",
    "    \"오늘 야근이야 또 아 진짜 힘들다 그래도 이번 프로젝트 끝나면 좀 쉴 수 있겠지\",\n",
    "    \"상사가 또 일 줬어 근데 뭐 그래도 인정해주니까 열심히 해야지 파이팅\",\n",
    "    \"퇴사하고 싶다 ㅋㅋ 아 농담이야 월급날이니까 참는거지 오늘 뭐 먹을까\",\n",
    "    \"야 우리 부장님 또 회식 잡았대 아 귀찮다 그래도 고기니까 ㅋㅋ 가자\",\n",
    "    \"아 오늘 진짜 일 많다 죽겠어 ㅋㅋ 그래도 퇴근하면 치맥이다 버텨보자\",\n",
    "    \"팀장님이 또 수정해달래 세번째야 근데 뭐 덕분에 더 좋아지긴 했어 감사하지\",\n",
    "    \"인사팀에서 면담하자고 했어 뭐래 아 그냥 만족도 조사래 놀랐잖아 ㅋㅋ\",\n",
    "    \"해고당할뻔 했어 ㅋㅋ 왜 아 늦잠자서 지각했는데 부장님이 웃으면서 넘어가줬어 휴\",\n",
    "    \"사직서 쓸뻔 했다 ㅋㅋ 왜 프린터가 안 돼서 30분 싸웠어 결국 고쳤어\",\n",
    "    \"회의 또 해 진짜 오늘만 세번째야 그래도 뭐 좋은 아이디어 나왔으니까 괜찮아\",\n",
    "    \"이 보고서 데이터 검증이 안 되어 있네요 출처 명시하고 수치 다시 확인해서 내일 오전까지 재출해주세요\",\n",
    "    \"납기가 이틀 남았습니다 지금 진행 상황 공유해주시고 지연 사유 있으면 미리 말씀해주세요\",\n",
    "    \"이번 기획안은 고객 니즈 분석이 부족합니다 시장조사 데이터 추가해서 보완해주세요\",\n",
    "    \"코드 리뷰 결과 예외 처리가 빠져있어요 에러 케이스 추가하고 테스트 코드도 작성해주세요\",\n",
    "    \"프레젠테이션 자료 글씨가 너무 작아요 핵심 메시지 위주로 슬라이드 재구성 부탁드립니다\",\n",
    "    \"회의 때 말씀드린 대로 일정 조정해서 공유해주세요 관련 부서 협의도 같이 진행해주시고요\",\n",
    "    \"이 디자인 컨셉은 브랜드 가이드라인과 맞지 않아요 색상과 폰트 가이드라인 확인하고 수정해주세요\",\n",
    "    \"주간 보고서 금요일까지 제출입니다 아직 안 내신 분들 오늘 중으로 부탁드려요\",\n",
    "    \"테스트 결과서에 버그 세 건 누락되어 있어요 전수 조사 다시 하고 정리해서 올려주세요\",\n",
    "    \"이번 제안서 경쟁사 분석 파트가 미흡합니다 벤치마킹 자료 보강해서 화요일까지 수정본 부탁합니다\",\n",
    "    \"야근비 신청하세요 오늘 늦게까지 수고했는데 당연히 받아야죠 내일은 좀 일찍 들어가세요\",\n",
    "    \"신입분 적응 잘 하고 계시죠 모르는 거 있으면 편하게 물어보세요 다들 도와줄 거예요\",\n",
    "    \"실수는 누구나 해요 중요한 건 같은 실수 반복하지 않는 거예요 이번 건 정리하고 넘어가죠\",\n",
    "    \"연차 사용하세요 쉴 때 쉬어야 업무 효율도 올라갑니다 일정 조율해서 신청하세요\",\n",
    "    \"팀 워크숍 날짜 정해야 해요 다음 주 금요일 어떨까요 의견 주세요\",\n",
    "    \"이번 분기 목표 달성률 85퍼센트입니다 남은 기간 집중해서 마무리합시다\",\n",
    "    \"재택근무 신청서 제출해주세요 사유란에 구체적으로 적어주시면 승인 빨리 됩니다\",\n",
    "    \"고객 응대 매뉴얼 업데이트했으니 확인해주세요 변경 사항 숙지하고 다음 주부터 적용합니다\",\n",
    "    \"업무 인수인계서 작성해주세요 후임자가 다음 주에 합류하니까 금요일까지 준비 부탁합니다\",\n",
    "    \"이번 프로젝트 회고 미팅 잡겠습니다 잘한 점과 개선점 각자 정리해서 가져오세요\",\n",
    "    \"수고하셨습니다 이번 달 성과 좋았어요 다음 달도 이 페이스 유지합시다\",\n",
    "    \"출장 보고서 양식 바뀌었어요 새 양식으로 다시 작성해서 제출해주세요\",\n",
    "    \"멘토링 프로그램 참여 의향 있으신 분 알려주세요 후배 개발자 성장에 큰 도움이 됩니다\",\n",
    "    \"다음 스프린트 백로그 정리했습니다 우선순위 확인하고 이의 있으면 스탠드업 때 말씀해주세요\",\n",
    "    \"보안 교육 이수 기한이 이번 주까지입니다 아직 안 하신 분들 꼭 완료해주세요\",\n",
    "    \"팀 회식 장소 투표해주세요 고기집이랑 횟집 중에 골라주시면 됩니다 오늘 중으로요\",\n",
    "    \"면접관 교육 신청하세요 채용 시즌 다가오니까 미리 준비합시다\",\n",
    "    \"KPI 중간 점검 결과 공유합니다 목표 대비 부족한 부분은 하반기에 집중 개선하겠습니다\",\n",
    "    \"회의록 공유해주세요 오늘 논의된 액션 아이템 정리해서 전체 공유 부탁합니다\",\n",
    "    \"이번 교육 프로그램 참석률이 낮았어요 다음에는 미리 일정 확인하고 참석해주세요\",\n",
    "\n",
    "    # HN-D: 기타괴롭힘 ↔ 친밀한 장난/공감/칭찬 (50개)\n",
    "    \"야 너 왜 혼자 밥 먹어 같이 먹자 아 몰랐어 미안 내일부터 같이 가자\",\n",
    "    \"쟤 좀 이상하지 않아 뭐가 아 그냥 오늘 옷 되게 특이하게 입었더라 멋있어\",\n",
    "    \"왕따 당하는 기분이야 ㅋㅋ 왜 아 오늘 점심 메뉴 나만 몰랐어 다들 알려줘\",\n",
    "    \"무시하지 마 ㅋㅋ 내 말 좀 들어봐 이번 여행 계획 진짜 좋거든 어디냐면\",\n",
    "    \"따돌리는거야 ㅋㅋ 왜 단톡방에 나만 안 넣었어 아 새로 만든거야 초대해줘\",\n",
    "    \"너네 나 없이 놀았지 ㅋㅋ 사진 봤어 아 미안 갑자기 된거야 다음엔 꼭 같이 가자\",\n",
    "    \"괴롭히지 마 ㅋㅋ 야 자꾸 내 별명 부르지 마 그거 초등학교 때 거잖아 창피해\",\n",
    "    \"소외감 느껴 ㅋㅋ 왜 너네 다 커플이라 나만 혼자야 아 나도 소개팅 시켜줘\",\n",
    "    \"야 쟤 왜 저래 아 그냥 원래 좀 조용한 애야 착해 알고 보면 진짜 재밌어\",\n",
    "    \"나만 빼고 다 아는거야 뭘 아 그 유행어 나만 모르나 알려줘 뭔데\",\n",
    "    \"야 너 오늘 좀 찐따 같다 ㅋㅋ 맞아 나 오늘 옷 잘못 입었나 봐 갈아입을까\",\n",
    "    \"키 작은 게 귀여워 ㅋㅋ 야 그러지 마 신경 쓰여 근데 진짜 아담하고 좋아\",\n",
    "    \"살 좀 빠졌다 다이어트 했어 응 한 달째 운동 중이야 대단하다 나도 같이 할래\",\n",
    "    \"안경 벗으니까 다른 사람 같아 ㅋㅋ 야 원래 눈이 이렇게 큰 거였어 예쁘다\",\n",
    "    \"너 진짜 못 생겼다 ㅋㅋ 야 장난이야 아 알아 나도 오늘 컨디션 안 좋아 ㅋㅋ\",\n",
    "    \"야 뚱뚱보 ㅋㅋ 야 그만 먹어 아 맛있는데 ㅋㅋ 같이 먹자 나도 줘봐\",\n",
    "    \"너 목소리 왜 그래 감기야 응 좀 아파 목 관리해 따뜻한 물 마셔 걱정된다\",\n",
    "    \"야 왜 이렇게 느려 빨리 와 ㅋㅋ 아 다리가 짧아서 천천히 가는 거야 기다려줘\",\n",
    "    \"너 피부 왜 이래 뭐 발랐어 아 팩 하고 왔어 오 좋아 보인다 뭐야 알려줘\",\n",
    "    \"머리 왜 이렇게 잘랐어 ㅋㅋ 아 미용실에서 이렇게 해줬어 근데 점점 마음에 들어\",\n",
    "    \"혼자 있고 싶어 왜 아 그냥 오늘 좀 피곤해서 내일 만나자 그래 푹 쉬어\",\n",
    "    \"무시당한 기분이야 ㅋㅋ 왜 아 내가 추천한 맛집을 아무도 안 가줘서 나만 좋아하나\",\n",
    "    \"같이 안 놀아줘 ㅋㅋ 누가 우리 강아지가 다른 강아지 싫어해서 혼자 놀아 귀여워\",\n",
    "    \"차별하는거 아니야 ㅋㅋ 왜 아 치킨 양념만 시키지 말고 후라이드도 시키자 나는 후라이드파\",\n",
    "    \"아무도 안 좋아해 ㅋㅋ 뭘 이 맛집을 아무도 모르더라 나만 알고 있어 데려갈까\",\n",
    "    \"야 너 진짜 웃기게 생겼다 ㅋㅋ 아 거울 봐 나도 알아 근데 사랑스럽잖아\",\n",
    "    \"얘 좀 이상하지 않아 ㅋㅋ 뭐가 아 갑자기 운동 시작해서 근데 좋은 거지 응원해\",\n",
    "    \"너 진짜 바보다 ㅋㅋ 왜 또 뭐 했어 아 비번 까먹었어 또 ㅋㅋ 같이 찾아보자\",\n",
    "    \"야 눈치 없다 ㅋㅋ 뭐가 아 분위기 파악 좀 해 근데 그게 네 매력이야\",\n",
    "    \"어이없다 진짜 ㅋㅋ 왜 아 약속 장소를 반대로 갔어 ㅋㅋ 택시 타고 와 내가 기다릴게\",\n",
    "    \"야 잘난 척 하지 마 ㅋㅋ 아 진짜 잘하긴 하잖아 부러워 나도 알려줘\",\n",
    "    \"충격이다 ㅋㅋ 왜 야 너 남자친구 생겼어 진짜 축하해 언제 소개시켜줘\",\n",
    "    \"야 네 패션 뭐야 ㅋㅋ 아 요즘 이런 게 유행이야 오 그래 난 모르겠다 근데 괜찮아 보여\",\n",
    "    \"소름 끼친다 ㅋㅋ 왜 야 우리 같은 옷 입고 왔어 트윈룩이다 사진 찍자\",\n",
    "    \"야 겁쟁이 ㅋㅋ 아 놀이기구 무서운 게 잘못이야 괜찮아 다른 거 타자 내가 같이 갈게\",\n",
    "    \"바보 같다 ㅋㅋ 왜 아 비 오는데 우산 안 가져왔어 나 같이 쓰자 좁지만 괜찮아\",\n",
    "    \"야 너 진짜 촌스럽다 ㅋㅋ 어디가 아 그 가방 근데 빈티지하고 예쁜데 어디서 샀어\",\n",
    "    \"찐따야 ㅋㅋ 야 그러지 마 알겠어 같이 가자 혼자 가기 싫어서 그런 거잖아\",\n",
    "    \"왜 이렇게 못 하냐 ㅋㅋ 게임 얘기야 아 연습해야겠다 같이 하자 알려줄게\",\n",
    "    \"쪽팔리다 ㅋㅋ 왜 야 길에서 넘어졌어 아 다쳤어 괜찮아 아니 자존심만 다쳤어 ㅋㅋ\",\n",
    "]\n",
    "normal_samples.extend(hard_negatives)\n",
    "print(f\"  -> {len(hard_negatives)}개 추가 (HN-A:50 HN-B:50 HN-C:50 HN-D:50)\")\n",
    "\n",
    "print(f\"\\n총 합성 일반대화 (필터 전): {len(normal_samples)}개\")\n",
    "\n",
    "# TAPT용 전체 텍스트 저장 (필터 전)\n",
    "tapt_texts_raw = list(normal_samples)  # 복사\n",
    "print(f\"TAPT용 raw 텍스트: {len(tapt_texts_raw)}개 (train + normal)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "품질 필터 적용:\n",
      "  품질 필터: 760개 제거, 22405개 통과\n",
      "\n",
      "중복 제거 (exact string):\n",
      "  22405 -> 22323개 (82개 제거)\n",
      "\n",
      "최종 train: 26273개\n",
      "label\n",
      "0      896\n",
      "1      981\n",
      "2      979\n",
      "3     1094\n",
      "4    22323\n",
      "Name: count, dtype: int64\n",
      "\n",
      "train prior: ['0.034', '0.037', '0.037', '0.042', '0.850']\n",
      "test prior:  ['0.078', '0.046', '0.042', '0.078', '0.756']\n",
      "cal ratio:   ['2.29', '1.23', '1.13', '1.87', '0.89']\n",
      "\n",
      "TAPT 학습용 전체 텍스트: 26773개\n",
      "데이터 체크포인트 저장 완료!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# STEP 3: 품질 필터 + 중복 제거 + 전처리 (v7 간소화)\n",
    "# ============================================================\n",
    "\n",
    "def preprocess(text):\n",
    "    text = str(text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = re.sub(r'[^가-힣a-zA-Z0-9ㄱ-ㅎㅏ-ㅣ\\s,.!?~ㅋㅎㅠㅜ]', '', text)\n",
    "    return text.strip()\n",
    "\n",
    "# 품질 필터\n",
    "def quality_filter(texts):\n",
    "    filtered = []\n",
    "    removed = 0\n",
    "    for t in texts:\n",
    "        t = str(t).strip()\n",
    "        if len(t) < MIN_TEXT_LEN or len(t) > MAX_TEXT_LEN:\n",
    "            removed += 1\n",
    "            continue\n",
    "        special_chars = sum(1 for c in t if not c.isalnum() and c != ' ')\n",
    "        if len(t) > 0 and special_chars / len(t) > MAX_SPECIAL_RATIO:\n",
    "            removed += 1\n",
    "            continue\n",
    "        if re.search(r'(.)\\1{4,}', t):\n",
    "            removed += 1\n",
    "            continue\n",
    "        filtered.append(t)\n",
    "    print(f\"  품질 필터: {removed}개 제거, {len(filtered)}개 통과\")\n",
    "    return filtered\n",
    "\n",
    "print(\"품질 필터 적용:\")\n",
    "normal_samples = quality_filter(normal_samples)\n",
    "\n",
    "# v7: 대규모 데이터이므로 exact string dedup (메모리 효율적)\n",
    "print(f\"\\n중복 제거 (exact string):\")\n",
    "before_dedup = len(normal_samples)\n",
    "seen = set()\n",
    "deduped = []\n",
    "for t in normal_samples:\n",
    "    normalized = t.strip().lower()\n",
    "    if normalized not in seen:\n",
    "        seen.add(normalized)\n",
    "        deduped.append(t)\n",
    "normal_samples = deduped\n",
    "print(f\"  {before_dedup} -> {len(normal_samples)}개 ({before_dedup - len(normal_samples)}개 제거)\")\n",
    "\n",
    "# 통합\n",
    "normal_df = pd.DataFrame({\n",
    "    'idx': [f'n_{i:04d}' for i in range(len(normal_samples))],\n",
    "    'class': '일반 대화',\n",
    "    'conversation': normal_samples\n",
    "})\n",
    "\n",
    "train_full = pd.concat([train_df[['idx', 'class', 'conversation']], normal_df],\n",
    "                       ignore_index=True)\n",
    "\n",
    "train_full['conversation'] = train_full['conversation'].apply(preprocess)\n",
    "test_df['conversation'] = test_df['conversation'].apply(preprocess)\n",
    "train_full['label'] = train_full['class'].map(CLASS2IDX).astype(int)\n",
    "\n",
    "print(f\"\\n최종 train: {len(train_full)}개\")\n",
    "label_dist = train_full['label'].value_counts().sort_index()\n",
    "print(label_dist)\n",
    "\n",
    "# Prior 계산\n",
    "train_prior = (label_dist / label_dist.sum()).values\n",
    "total_test = sum(EST_TEST_DIST.values())\n",
    "test_prior = np.array([EST_TEST_DIST[i] / total_test for i in range(NUM_CLASSES)])\n",
    "cal_ratio = test_prior / (train_prior + 1e-8)\n",
    "print(f\"\\ntrain prior: {[f'{p:.3f}' for p in train_prior]}\")\n",
    "print(f\"test prior:  {[f'{p:.3f}' for p in test_prior]}\")\n",
    "print(f\"cal ratio:   {[f'{r:.2f}' for r in cal_ratio]}\")\n",
    "\n",
    "# TAPT용 전체 텍스트 구성 (train + test + normal)\n",
    "all_tapt_texts = list(train_full['conversation'].values) + list(test_df['conversation'].values)\n",
    "print(f\"\\nTAPT 학습용 전체 텍스트: {len(all_tapt_texts)}개\")\n",
    "\n",
    "# 데이터 체크포인트 저장\n",
    "train_full.to_csv(os.path.join(CKPT_DIR, 'train_full.csv'), index=False)\n",
    "np.save(os.path.join(CKPT_DIR, 'train_prior.npy'), train_prior)\n",
    "np.save(os.path.join(CKPT_DIR, 'test_prior.npy'), test_prior)\n",
    "np.save(os.path.join(CKPT_DIR, 'cal_ratio.npy'), cal_ratio)\n",
    "print(\"데이터 체크포인트 저장 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[v7-1] TAPT 시작: klue/bert-base\n",
      "  학습 데이터: 26773개 텍스트\n",
      "  Epochs: 5, LR: 2e-05, MLM prob: 0.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|██████████| 202/202 [00:00<00:00, 1279.66it/s, Materializing param=cls.predictions.transform.dense.weight]                 \n",
      "\u001b[1mBertForMaskedLM LOAD REPORT\u001b[0m from: klue/bert-base\n",
      "Key                          | Status     |  | \n",
      "-----------------------------+------------+--+-\n",
      "bert.embeddings.position_ids | UNEXPECTED |  | \n",
      "cls.seq_relationship.weight  | UNEXPECTED |  | \n",
      "bert.pooler.dense.weight     | UNEXPECTED |  | \n",
      "bert.pooler.dense.bias       | UNEXPECTED |  | \n",
      "cls.seq_relationship.bias    | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  TAPT Epoch 1/5 | Loss: 1.7416 | 2.4분\n",
      "  TAPT Epoch 2/5 | Loss: 1.5541 | 4.8분\n",
      "  TAPT Epoch 3/5 | Loss: 1.5098 | 7.2분\n",
      "  TAPT Epoch 4/5 | Loss: 1.4746 | 9.6분\n",
      "  TAPT Epoch 5/5 | Loss: 1.4502 | 12.0분\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Writing model shards: 100%|██████████| 1/1 [00:00<00:00,  1.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  TAPT 완료! 12.0분\n",
      "  저장: /home/ubuntu/lambda-fs/v7_ckpts/tapt_model\n",
      "\n",
      "TAPT 모델 준비 완료: /home/ubuntu/lambda-fs/v7_ckpts/tapt_model\n",
      "Fine-tune 모델: KLUE-BERT-TAPT\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# STEP 3.5: [v7-1] TAPT (Task-Adaptive Pre-Training)\n",
    "# 참고: \"Don't Stop Pretraining\" (Gururangan et al., 2020)\n",
    "# 참고: 0.882 달성자 - klue/bert-base + TAPT\n",
    "# ============================================================\n",
    "TAPT_CKPT = os.path.join(CKPT_DIR, 'tapt_done.flag')\n",
    "\n",
    "if os.path.exists(TAPT_SAVE_DIR) and os.path.exists(TAPT_CKPT):\n",
    "    print(\"[체크포인트] TAPT 모델 이미 존재! 로드합니다.\")\n",
    "    print(f\"  경로: {TAPT_SAVE_DIR}\")\n",
    "else:\n",
    "    print(f\"[v7-1] TAPT 시작: {BASE_MODEL}\")\n",
    "    print(f\"  학습 데이터: {len(all_tapt_texts)}개 텍스트\")\n",
    "    print(f\"  Epochs: {TAPT_EPOCHS}, LR: {TAPT_LR}, MLM prob: {TAPT_MLM_PROB}\")\n",
    "\n",
    "    # TAPT용 Dataset\n",
    "    class TAPTDataset(Dataset):\n",
    "        def __init__(self, texts, tokenizer, max_len=256):\n",
    "            self.encodings = tokenizer(\n",
    "                texts, truncation=True, max_length=max_len,\n",
    "                padding='max_length', return_tensors='pt'\n",
    "            )\n",
    "        def __len__(self):\n",
    "            return self.encodings['input_ids'].shape[0]\n",
    "        def __getitem__(self, idx):\n",
    "            return {k: v[idx] for k, v in self.encodings.items()}\n",
    "\n",
    "    tapt_tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL)\n",
    "    tapt_model = AutoModelForMaskedLM.from_pretrained(BASE_MODEL).to(DEVICE)\n",
    "\n",
    "    # 배치 처리로 메모리 절약\n",
    "    tapt_ds = TAPTDataset(all_tapt_texts, tapt_tokenizer, MAX_LEN)\n",
    "    data_collator = DataCollatorForLanguageModeling(\n",
    "        tokenizer=tapt_tokenizer, mlm=True, mlm_probability=TAPT_MLM_PROB\n",
    "    )\n",
    "    tapt_dl = DataLoader(\n",
    "        tapt_ds, batch_size=TAPT_BATCH_SIZE, shuffle=True,\n",
    "        collate_fn=data_collator\n",
    "    )\n",
    "\n",
    "    tapt_opt = torch.optim.AdamW(tapt_model.parameters(), lr=TAPT_LR,\n",
    "                                  weight_decay=WEIGHT_DECAY)\n",
    "    total_steps = len(tapt_dl) * TAPT_EPOCHS\n",
    "    tapt_sched = get_linear_schedule_with_warmup(\n",
    "        tapt_opt, int(total_steps * 0.1), total_steps\n",
    "    )\n",
    "\n",
    "    tapt_start = time.time()\n",
    "    for ep in range(TAPT_EPOCHS):\n",
    "        tapt_model.train()\n",
    "        ep_loss = 0\n",
    "        for step, batch in enumerate(tapt_dl):\n",
    "            batch = {k: v.to(DEVICE) for k, v in batch.items()}\n",
    "            outputs = tapt_model(**batch)\n",
    "            loss = outputs.loss\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(tapt_model.parameters(), MAX_GRAD_NORM)\n",
    "            tapt_opt.step()\n",
    "            tapt_sched.step()\n",
    "            tapt_opt.zero_grad()\n",
    "            ep_loss += loss.item()\n",
    "        avg_loss = ep_loss / len(tapt_dl)\n",
    "        elapsed = (time.time() - tapt_start) / 60\n",
    "        print(f\"  TAPT Epoch {ep+1}/{TAPT_EPOCHS} | Loss: {avg_loss:.4f} | {elapsed:.1f}분\")\n",
    "\n",
    "    # TAPT 모델 저장\n",
    "    os.makedirs(TAPT_SAVE_DIR, exist_ok=True)\n",
    "    tapt_model.save_pretrained(TAPT_SAVE_DIR)\n",
    "    tapt_tokenizer.save_pretrained(TAPT_SAVE_DIR)\n",
    "\n",
    "    # 완료 플래그\n",
    "    with open(TAPT_CKPT, 'w') as f:\n",
    "        f.write(f'done in {(time.time()-tapt_start)/60:.1f} min')\n",
    "\n",
    "    total_min = (time.time() - tapt_start) / 60\n",
    "    print(f\"\\n  TAPT 완료! {total_min:.1f}분\")\n",
    "    print(f\"  저장: {TAPT_SAVE_DIR}\")\n",
    "\n",
    "    del tapt_model, tapt_opt, tapt_sched, tapt_dl, tapt_ds\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "print(f\"\\nTAPT 모델 준비 완료: {TAPT_SAVE_DIR}\")\n",
    "print(f\"Fine-tune 모델: {MODEL_CONFIGS[0]['short']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "클래스 정의 완료\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# STEP 4: 모델 클래스 정의\n",
    "# ============================================================\n",
    "class DKTCDataset(Dataset):\n",
    "    def __init__(self, texts, labels=None, tokenizer=None, max_len=256):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    def __getitem__(self, idx):\n",
    "        encoding = self.tokenizer(\n",
    "            str(self.texts[idx]), max_length=self.max_len,\n",
    "            padding='max_length', truncation=True, return_tensors='pt'\n",
    "        )\n",
    "        item = {\n",
    "            'input_ids': encoding['input_ids'].squeeze(0),\n",
    "            'attention_mask': encoding['attention_mask'].squeeze(0),\n",
    "        }\n",
    "        if 'token_type_ids' in encoding:\n",
    "            item['token_type_ids'] = encoding['token_type_ids'].squeeze(0)\n",
    "        if self.labels is not None:\n",
    "            item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return item\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=None, gamma=2.0, label_smoothing=0.0, reduction='mean'):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.label_smoothing = label_smoothing\n",
    "        self.reduction = reduction\n",
    "    def forward(self, inputs, targets):\n",
    "        ce = F.cross_entropy(inputs, targets, weight=self.alpha,\n",
    "                             reduction='none', label_smoothing=self.label_smoothing)\n",
    "        pt = torch.exp(-F.cross_entropy(inputs, targets, reduction='none'))\n",
    "        fl = ((1 - pt) ** self.gamma) * ce\n",
    "        return fl.mean() if self.reduction == 'mean' else fl\n",
    "\n",
    "def compute_rdrop_loss(l1, l2, labels, loss_fn, alpha=0.7):\n",
    "    ce = (loss_fn(l1, labels) + loss_fn(l2, labels)) / 2\n",
    "    p, q = F.log_softmax(l1, -1), F.log_softmax(l2, -1)\n",
    "    kl = (F.kl_div(p, q.exp(), reduction='batchmean') +\n",
    "          F.kl_div(q, p.exp(), reduction='batchmean')) / 2\n",
    "    return ce + alpha * kl\n",
    "\n",
    "class FGM:\n",
    "    def __init__(self, model, epsilon=1.0, emb_name='word_embeddings'):\n",
    "        self.model, self.epsilon, self.emb_name, self.backup = model, epsilon, emb_name, {}\n",
    "    def attack(self):\n",
    "        for n, p in self.model.named_parameters():\n",
    "            if p.requires_grad and self.emb_name in n:\n",
    "                self.backup[n] = p.data.clone()\n",
    "                if p.grad is not None:\n",
    "                    norm = torch.norm(p.grad)\n",
    "                    if norm != 0 and not torch.isnan(norm):\n",
    "                        p.data.add_(self.epsilon * p.grad / norm)\n",
    "    def restore(self):\n",
    "        for n, p in self.model.named_parameters():\n",
    "            if p.requires_grad and self.emb_name in n and n in self.backup:\n",
    "                p.data = self.backup[n]\n",
    "        self.backup = {}\n",
    "\n",
    "class EMA:\n",
    "    def __init__(self, model, decay=0.999):\n",
    "        self.model, self.decay = model, decay\n",
    "        self.shadow = {n: p.data.clone() for n, p in model.named_parameters() if p.requires_grad}\n",
    "        self.backup = {}\n",
    "    def update(self):\n",
    "        for n, p in self.model.named_parameters():\n",
    "            if p.requires_grad:\n",
    "                self.shadow[n] = (1 - self.decay) * p.data + self.decay * self.shadow[n]\n",
    "    def apply_shadow(self):\n",
    "        for n, p in self.model.named_parameters():\n",
    "            if p.requires_grad:\n",
    "                self.backup[n] = p.data.clone()\n",
    "                p.data = self.shadow[n]\n",
    "    def restore(self):\n",
    "        for n, p in self.model.named_parameters():\n",
    "            if p.requires_grad:\n",
    "                p.data = self.backup[n]\n",
    "        self.backup = {}\n",
    "\n",
    "def get_llrd_optimizer(model, lr=2e-5, weight_decay=0.01, llrd_factor=0.95):\n",
    "    no_decay = ['bias', 'LayerNorm.weight', 'LayerNorm.bias']\n",
    "    backbone = getattr(model, 'electra', getattr(model, 'bert', None))\n",
    "    if backbone is None:\n",
    "        return torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    layers = [backbone.embeddings] + list(backbone.encoder.layer)\n",
    "    n = len(layers)\n",
    "    params = []\n",
    "    for i, layer in enumerate(layers):\n",
    "        layer_lr = lr * (llrd_factor ** (n - 1 - i))\n",
    "        params.extend([\n",
    "            {'params': [p for nm, p in layer.named_parameters()\n",
    "                       if not any(nd in nm for nd in no_decay) and p.requires_grad],\n",
    "             'lr': layer_lr, 'weight_decay': weight_decay},\n",
    "            {'params': [p for nm, p in layer.named_parameters()\n",
    "                       if any(nd in nm for nd in no_decay) and p.requires_grad],\n",
    "             'lr': layer_lr, 'weight_decay': 0.0},\n",
    "        ])\n",
    "    for nm, p in model.named_parameters():\n",
    "        if 'classifier' in nm and p.requires_grad:\n",
    "            wd = 0.0 if any(nd in nm for nd in no_decay) else weight_decay\n",
    "            params.append({'params': [p], 'lr': lr, 'weight_decay': wd})\n",
    "    return torch.optim.AdamW(params)\n",
    "\n",
    "print(\"클래스 정의 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "함수 정의 완료\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# STEP 5: 학습/검증/예측/보정 함수\n",
    "# ============================================================\n",
    "def train_one_epoch(model, dl, opt, sched, loss_fn, fgm=None, ema=None,\n",
    "                    use_rdrop=True, rdrop_alpha=0.7):\n",
    "    model.train()\n",
    "    total_loss, all_p, all_l = 0, [], []\n",
    "    for batch in dl:\n",
    "        ids = batch['input_ids'].to(DEVICE)\n",
    "        mask = batch['attention_mask'].to(DEVICE)\n",
    "        labels = batch['labels'].to(DEVICE)\n",
    "        kw = {'input_ids': ids, 'attention_mask': mask}\n",
    "        if 'token_type_ids' in batch:\n",
    "            kw['token_type_ids'] = batch['token_type_ids'].to(DEVICE)\n",
    "        if use_rdrop:\n",
    "            o1, o2 = model(**kw), model(**kw)\n",
    "            loss = compute_rdrop_loss(o1.logits, o2.logits, labels, loss_fn, rdrop_alpha)\n",
    "            logits = o1.logits\n",
    "        else:\n",
    "            o = model(**kw)\n",
    "            logits, loss = o.logits, loss_fn(o.logits, labels)\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        if fgm:\n",
    "            fgm.attack()\n",
    "            adv_loss = loss_fn(model(**kw).logits, labels)\n",
    "            adv_loss.backward()\n",
    "            fgm.restore()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), MAX_GRAD_NORM)\n",
    "        opt.step()\n",
    "        sched.step()\n",
    "        if ema:\n",
    "            ema.update()\n",
    "        total_loss += loss.item()\n",
    "        all_p.extend(torch.argmax(logits, -1).cpu().numpy())\n",
    "        all_l.extend(labels.cpu().numpy())\n",
    "    return total_loss / len(dl), accuracy_score(all_l, all_p), f1_score(all_l, all_p, average='macro')\n",
    "\n",
    "def evaluate(model, dl, loss_fn):\n",
    "    model.eval()\n",
    "    total_loss, all_p, all_l = 0, [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in dl:\n",
    "            ids = batch['input_ids'].to(DEVICE)\n",
    "            mask = batch['attention_mask'].to(DEVICE)\n",
    "            labels = batch['labels'].to(DEVICE)\n",
    "            kw = {'input_ids': ids, 'attention_mask': mask}\n",
    "            if 'token_type_ids' in batch:\n",
    "                kw['token_type_ids'] = batch['token_type_ids'].to(DEVICE)\n",
    "            o = model(**kw)\n",
    "            total_loss += loss_fn(o.logits, labels).item()\n",
    "            all_p.extend(torch.argmax(o.logits, -1).cpu().numpy())\n",
    "            all_l.extend(labels.cpu().numpy())\n",
    "    n = len(dl)\n",
    "    return total_loss / n, accuracy_score(all_l, all_p), f1_score(all_l, all_p, average='macro'), all_p, all_l\n",
    "\n",
    "def predict_proba(model, dl):\n",
    "    model.eval()\n",
    "    probs = []\n",
    "    with torch.no_grad():\n",
    "        for batch in dl:\n",
    "            ids = batch['input_ids'].to(DEVICE)\n",
    "            mask = batch['attention_mask'].to(DEVICE)\n",
    "            kw = {'input_ids': ids, 'attention_mask': mask}\n",
    "            if 'token_type_ids' in batch:\n",
    "                kw['token_type_ids'] = batch['token_type_ids'].to(DEVICE)\n",
    "            probs.append(F.softmax(model(**kw).logits, -1).cpu().numpy())\n",
    "    return np.concatenate(probs)\n",
    "\n",
    "def calibrate_probs(probs, tp, ep):\n",
    "    w = ep / (tp + 1e-8)\n",
    "    c = probs * w[np.newaxis, :]\n",
    "    return c / c.sum(axis=1, keepdims=True)\n",
    "\n",
    "def optimize_thresholds(oof_probs, oof_labels, num_classes=5):\n",
    "    best_t = np.ones(num_classes)\n",
    "    best_f1 = f1_score(oof_labels, np.argmax(oof_probs, 1), average='macro')\n",
    "    print(f\"  기본 OOF F1: {best_f1:.4f}\")\n",
    "    for cls in range(num_classes):\n",
    "        for t in np.arange(0.3, 3.01, 0.05):\n",
    "            adj = oof_probs.copy()\n",
    "            adj[:, cls] *= t\n",
    "            f = f1_score(oof_labels, np.argmax(adj, 1), average='macro')\n",
    "            if f > best_f1:\n",
    "                best_f1, best_t[cls] = f, t\n",
    "    print(f\"  최적화 후 OOF F1: {best_f1:.4f}\")\n",
    "    print(f\"  Thresholds: {[f'{t:.2f}' for t in best_t]}\")\n",
    "    return best_t\n",
    "\n",
    "print(\"함수 정의 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "  모델: KLUE-BERT-TAPT\n",
      "  경로: /home/ubuntu/lambda-fs/v7_ckpts/tapt_model\n",
      "============================================================\n",
      "\n",
      "  --- KLUE-BERT-TAPT Fold 1/5 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|██████████| 197/197 [00:00<00:00, 726.02it/s, Materializing param=bert.encoder.layer.11.output.dense.weight]              \n",
      "\u001b[1mBertForSequenceClassification LOAD REPORT\u001b[0m from: /home/ubuntu/lambda-fs/v7_ckpts/tapt_model\n",
      "Key                                        | Status     | \n",
      "-------------------------------------------+------------+-\n",
      "cls.predictions.transform.dense.weight     | UNEXPECTED | \n",
      "cls.predictions.transform.LayerNorm.weight | UNEXPECTED | \n",
      "cls.predictions.transform.LayerNorm.bias   | UNEXPECTED | \n",
      "cls.predictions.transform.dense.bias       | UNEXPECTED | \n",
      "cls.predictions.bias                       | UNEXPECTED | \n",
      "bert.pooler.dense.bias                     | MISSING    | \n",
      "bert.pooler.dense.weight                   | MISSING    | \n",
      "classifier.bias                            | MISSING    | \n",
      "classifier.weight                          | MISSING    | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
      "- MISSING\u001b[3m\t:those params were newly initialized because missing from the checkpoint. Consider training on your downstream task.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Ep 1/5 | Train F1: 0.6552 | Val F1: 0.8829  *\n",
      "    Ep 2/5 | Train F1: 0.9178 | Val F1: 0.9125  *\n",
      "    Ep 3/5 | Train F1: 0.9515 | Val F1: 0.9224  *\n",
      "    Ep 4/5 | Train F1: 0.9751 | Val F1: 0.9234  *\n",
      "    Ep 5/5 | Train F1: 0.9878 | Val F1: 0.9264  *\n",
      "    >> Best Val F1: 0.9264\n",
      "    Fold 1 완료: 22.3분 | 남은 예상: 89.3분\n",
      "    체크포인트 저장 완료 (Fold 1/5)\n",
      "\n",
      "  --- KLUE-BERT-TAPT Fold 2/5 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|██████████| 197/197 [00:00<00:00, 895.02it/s, Materializing param=bert.encoder.layer.11.output.dense.weight]              \n",
      "\u001b[1mBertForSequenceClassification LOAD REPORT\u001b[0m from: /home/ubuntu/lambda-fs/v7_ckpts/tapt_model\n",
      "Key                                        | Status     | \n",
      "-------------------------------------------+------------+-\n",
      "cls.predictions.transform.dense.weight     | UNEXPECTED | \n",
      "cls.predictions.transform.LayerNorm.weight | UNEXPECTED | \n",
      "cls.predictions.transform.LayerNorm.bias   | UNEXPECTED | \n",
      "cls.predictions.transform.dense.bias       | UNEXPECTED | \n",
      "cls.predictions.bias                       | UNEXPECTED | \n",
      "bert.pooler.dense.bias                     | MISSING    | \n",
      "bert.pooler.dense.weight                   | MISSING    | \n",
      "classifier.bias                            | MISSING    | \n",
      "classifier.weight                          | MISSING    | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
      "- MISSING\u001b[3m\t:those params were newly initialized because missing from the checkpoint. Consider training on your downstream task.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Ep 1/5 | Train F1: 0.6502 | Val F1: 0.8807  *\n",
      "    Ep 2/5 | Train F1: 0.9117 | Val F1: 0.9154  *\n",
      "    Ep 3/5 | Train F1: 0.9561 | Val F1: 0.9217  *\n",
      "    Ep 4/5 | Train F1: 0.9773 | Val F1: 0.9280  *\n",
      "    Ep 5/5 | Train F1: 0.9869 | Val F1: 0.9308  *\n",
      "    >> Best Val F1: 0.9308\n",
      "    Fold 2 완료: 22.3분 | 남은 예상: 66.9분\n",
      "    체크포인트 저장 완료 (Fold 2/5)\n",
      "\n",
      "  --- KLUE-BERT-TAPT Fold 3/5 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|██████████| 197/197 [00:00<00:00, 991.74it/s, Materializing param=bert.encoder.layer.11.output.dense.weight]              \n",
      "\u001b[1mBertForSequenceClassification LOAD REPORT\u001b[0m from: /home/ubuntu/lambda-fs/v7_ckpts/tapt_model\n",
      "Key                                        | Status     | \n",
      "-------------------------------------------+------------+-\n",
      "cls.predictions.transform.dense.weight     | UNEXPECTED | \n",
      "cls.predictions.transform.LayerNorm.weight | UNEXPECTED | \n",
      "cls.predictions.transform.LayerNorm.bias   | UNEXPECTED | \n",
      "cls.predictions.transform.dense.bias       | UNEXPECTED | \n",
      "cls.predictions.bias                       | UNEXPECTED | \n",
      "bert.pooler.dense.bias                     | MISSING    | \n",
      "bert.pooler.dense.weight                   | MISSING    | \n",
      "classifier.bias                            | MISSING    | \n",
      "classifier.weight                          | MISSING    | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
      "- MISSING\u001b[3m\t:those params were newly initialized because missing from the checkpoint. Consider training on your downstream task.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Ep 1/5 | Train F1: 0.6601 | Val F1: 0.8791  *\n",
      "    Ep 2/5 | Train F1: 0.9087 | Val F1: 0.9249  *\n",
      "    Ep 3/5 | Train F1: 0.9481 | Val F1: 0.9310  *\n",
      "    Ep 4/5 | Train F1: 0.9736 | Val F1: 0.9383  *\n",
      "    Ep 5/5 | Train F1: 0.9849 | Val F1: 0.9389  *\n",
      "    >> Best Val F1: 0.9389\n",
      "    Fold 3 완료: 22.4분 | 남은 예상: 44.7분\n",
      "    체크포인트 저장 완료 (Fold 3/5)\n",
      "\n",
      "  --- KLUE-BERT-TAPT Fold 4/5 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|██████████| 197/197 [00:00<00:00, 814.02it/s, Materializing param=bert.encoder.layer.11.output.dense.weight]              \n",
      "\u001b[1mBertForSequenceClassification LOAD REPORT\u001b[0m from: /home/ubuntu/lambda-fs/v7_ckpts/tapt_model\n",
      "Key                                        | Status     | \n",
      "-------------------------------------------+------------+-\n",
      "cls.predictions.transform.dense.weight     | UNEXPECTED | \n",
      "cls.predictions.transform.LayerNorm.weight | UNEXPECTED | \n",
      "cls.predictions.transform.LayerNorm.bias   | UNEXPECTED | \n",
      "cls.predictions.transform.dense.bias       | UNEXPECTED | \n",
      "cls.predictions.bias                       | UNEXPECTED | \n",
      "bert.pooler.dense.bias                     | MISSING    | \n",
      "bert.pooler.dense.weight                   | MISSING    | \n",
      "classifier.bias                            | MISSING    | \n",
      "classifier.weight                          | MISSING    | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
      "- MISSING\u001b[3m\t:those params were newly initialized because missing from the checkpoint. Consider training on your downstream task.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Ep 1/5 | Train F1: 0.6266 | Val F1: 0.8908  *\n",
      "    Ep 2/5 | Train F1: 0.9144 | Val F1: 0.9192  *\n",
      "    Ep 3/5 | Train F1: 0.9510 | Val F1: 0.9297  *\n",
      "    Ep 4/5 | Train F1: 0.9722 | Val F1: 0.9337  *\n",
      "    Ep 5/5 | Train F1: 0.9883 | Val F1: 0.9357  *\n",
      "    >> Best Val F1: 0.9357\n",
      "    Fold 4 완료: 22.4분 | 남은 예상: 22.4분\n",
      "    체크포인트 저장 완료 (Fold 4/5)\n",
      "\n",
      "  --- KLUE-BERT-TAPT Fold 5/5 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|██████████| 197/197 [00:00<00:00, 1274.68it/s, Materializing param=bert.encoder.layer.11.output.dense.weight]             \n",
      "\u001b[1mBertForSequenceClassification LOAD REPORT\u001b[0m from: /home/ubuntu/lambda-fs/v7_ckpts/tapt_model\n",
      "Key                                        | Status     | \n",
      "-------------------------------------------+------------+-\n",
      "cls.predictions.transform.dense.weight     | UNEXPECTED | \n",
      "cls.predictions.transform.LayerNorm.weight | UNEXPECTED | \n",
      "cls.predictions.transform.LayerNorm.bias   | UNEXPECTED | \n",
      "cls.predictions.transform.dense.bias       | UNEXPECTED | \n",
      "cls.predictions.bias                       | UNEXPECTED | \n",
      "bert.pooler.dense.bias                     | MISSING    | \n",
      "bert.pooler.dense.weight                   | MISSING    | \n",
      "classifier.bias                            | MISSING    | \n",
      "classifier.weight                          | MISSING    | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
      "- MISSING\u001b[3m\t:those params were newly initialized because missing from the checkpoint. Consider training on your downstream task.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Ep 1/5 | Train F1: 0.6857 | Val F1: 0.8866  *\n",
      "    Ep 2/5 | Train F1: 0.9075 | Val F1: 0.9131  *\n",
      "    Ep 3/5 | Train F1: 0.9500 | Val F1: 0.9233  *\n",
      "    Ep 4/5 | Train F1: 0.9734 | Val F1: 0.9262  *\n",
      "    Ep 5/5 | Train F1: 0.9863 | Val F1: 0.9352  *\n",
      "    >> Best Val F1: 0.9352\n",
      "    Fold 5 완료: 38.6분 | 남은 예상: 0.0분\n",
      "    체크포인트 저장 완료 (Fold 5/5)\n",
      "\n",
      "총 학습 시간: 128.0분\n",
      "\n",
      "학습 완료! 5 fold 결과\n",
      "  KLUE-BERT-TAPT Fold 1: Val F1 = 0.9264\n",
      "  KLUE-BERT-TAPT Fold 2: Val F1 = 0.9308\n",
      "  KLUE-BERT-TAPT Fold 3: Val F1 = 0.9389\n",
      "  KLUE-BERT-TAPT Fold 4: Val F1 = 0.9357\n",
      "  KLUE-BERT-TAPT Fold 5: Val F1 = 0.9352\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# STEP 6: K-Fold 학습 (TAPT 모델 기반, 체크포인트 저장/복구)\n",
    "# ============================================================\n",
    "CKPT_PATH = os.path.join(CKPT_DIR, 'v7_checkpoint.pkl')\n",
    "oof_labels = train_full['label'].values.copy()\n",
    "\n",
    "# -- 초기화 --\n",
    "all_model_probs = []\n",
    "all_fold_results = []\n",
    "all_oof_probs = []\n",
    "start_fold = 0\n",
    "m_oof = np.zeros((len(train_full), NUM_CLASSES))\n",
    "training_done = False\n",
    "\n",
    "# -- 체크포인트 확인 --\n",
    "if os.path.exists(CKPT_PATH):\n",
    "    try:\n",
    "        with open(CKPT_PATH, 'rb') as f:\n",
    "            ckpt = pickle.load(f)\n",
    "        if ckpt.get('complete', False):\n",
    "            all_model_probs = ckpt['all_model_probs']\n",
    "            all_fold_results = ckpt['all_fold_results']\n",
    "            all_oof_probs = ckpt['all_oof_probs']\n",
    "            oof_labels = ckpt['oof_labels']\n",
    "            training_done = True\n",
    "            print(\"[체크포인트] 이전 학습 완료! 로드 성공\")\n",
    "            for r in all_fold_results:\n",
    "                print(f\"  {r['model']} Fold {r['fold']}: Val F1 = {r['best_val_f1']:.4f}\")\n",
    "        elif ckpt.get('data_len') == len(train_full):\n",
    "            all_model_probs = ckpt['all_model_probs']\n",
    "            all_fold_results = ckpt['all_fold_results']\n",
    "            m_oof = ckpt['m_oof']\n",
    "            start_fold = ckpt['next_fold']\n",
    "            print(f\"[체크포인트] Fold {start_fold+1}/{N_FOLDS}부터 재개합니다\")\n",
    "            for r in all_fold_results:\n",
    "                print(f\"  (완료) {r['model']} Fold {r['fold']}: Val F1 = {r['best_val_f1']:.4f}\")\n",
    "        else:\n",
    "            print(\"[체크포인트] 데이터 크기 변경 감지. 처음부터 학습합니다.\")\n",
    "            os.remove(CKPT_PATH)\n",
    "    except Exception as e:\n",
    "        print(f\"[체크포인트] 로드 실패: {e}. 처음부터 학습합니다.\")\n",
    "\n",
    "if not training_done:\n",
    "    t_start = time.time()\n",
    "    mn = MODEL_CONFIGS[0]['name']\n",
    "    ms = MODEL_CONFIGS[0]['short']\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"  모델: {ms}\")\n",
    "    print(f\"  경로: {mn}\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    tok = AutoTokenizer.from_pretrained(mn)\n",
    "    test_ds = DKTCDataset(test_df['conversation'].values, None, tok, MAX_LEN)\n",
    "    test_dl = DataLoader(test_ds, batch_size=BATCH_SIZE)\n",
    "    skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=SEED)\n",
    "\n",
    "    for fold, (ti, vi) in enumerate(skf.split(train_full, train_full['label'])):\n",
    "        if fold < start_fold:\n",
    "            print(f\"\\n  --- {ms} Fold {fold+1}/{N_FOLDS} (체크포인트 건너뜀) ---\")\n",
    "            continue\n",
    "\n",
    "        fold_start = time.time()\n",
    "        print(f\"\\n  --- {ms} Fold {fold+1}/{N_FOLDS} ---\")\n",
    "        ft, fv = train_full.iloc[ti], train_full.iloc[vi]\n",
    "        tr_ds = DKTCDataset(ft['conversation'].values, ft['label'].values, tok, MAX_LEN)\n",
    "        va_ds = DKTCDataset(fv['conversation'].values, fv['label'].values, tok, MAX_LEN)\n",
    "        tr_dl = DataLoader(tr_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "        va_dl = DataLoader(va_ds, batch_size=BATCH_SIZE)\n",
    "\n",
    "        lc = ft['label'].value_counts().sort_index()\n",
    "        cw = torch.tensor([len(ft) / (NUM_CLASSES * c) for c in lc.values],\n",
    "                          dtype=torch.float32).to(DEVICE)\n",
    "\n",
    "        # Dynamic Class Weight\n",
    "        test_weight_boost = torch.tensor(cal_ratio, dtype=torch.float32).to(DEVICE)\n",
    "        adjusted_cw = cw * (test_weight_boost ** 0.3)\n",
    "        adjusted_cw = adjusted_cw / adjusted_cw.mean()\n",
    "\n",
    "        lf = FocalLoss(alpha=adjusted_cw, gamma=2.0,\n",
    "                       label_smoothing=LABEL_SMOOTHING).to(DEVICE)\n",
    "        mdl = AutoModelForSequenceClassification.from_pretrained(\n",
    "            mn, num_labels=NUM_CLASSES).to(DEVICE)\n",
    "        opt = get_llrd_optimizer(mdl, LR, WEIGHT_DECAY, LLRD_FACTOR)\n",
    "        ts = len(tr_dl) * EPOCHS\n",
    "        sched = get_linear_schedule_with_warmup(opt, int(ts * WARMUP_RATIO), ts)\n",
    "        fgm_obj = FGM(mdl, FGM_EPSILON)\n",
    "        ema_obj = EMA(mdl, EMA_DECAY)\n",
    "        best_f1, best_st = 0, None\n",
    "\n",
    "        for ep in range(EPOCHS):\n",
    "            tl, ta, tf = train_one_epoch(\n",
    "                mdl, tr_dl, opt, sched, lf, fgm_obj, ema_obj, True, 0.7)\n",
    "            ema_obj.apply_shadow()\n",
    "            vl, va, vf, _, _ = evaluate(mdl, va_dl, lf)\n",
    "            if vf > best_f1:\n",
    "                best_f1 = vf\n",
    "                best_st = {k: v.cpu().clone() for k, v in mdl.state_dict().items()}\n",
    "            ema_obj.restore()\n",
    "            print(f\"    Ep {ep+1}/{EPOCHS} | Train F1: {tf:.4f} | \"\n",
    "                  f\"Val F1: {vf:.4f}{'  *' if vf >= best_f1 else ''}\")\n",
    "\n",
    "        print(f\"    >> Best Val F1: {best_f1:.4f}\")\n",
    "        mdl.load_state_dict(best_st)\n",
    "        mdl.to(DEVICE)\n",
    "        all_model_probs.append(predict_proba(mdl, test_dl))\n",
    "        m_oof[vi] = predict_proba(mdl, va_dl)\n",
    "        all_fold_results.append({\n",
    "            'model': ms, 'fold': fold + 1, 'best_val_f1': best_f1})\n",
    "\n",
    "        # Fold 체크포인트 저장\n",
    "        fold_time = (time.time() - fold_start) / 60\n",
    "        remaining = (N_FOLDS - fold - 1) * fold_time\n",
    "        print(f\"    Fold {fold+1} 완료: {fold_time:.1f}분 | \"\n",
    "              f\"남은 예상: {remaining:.1f}분\")\n",
    "\n",
    "        ckpt_data = {\n",
    "            'all_model_probs': all_model_probs,\n",
    "            'all_fold_results': all_fold_results,\n",
    "            'm_oof': m_oof,\n",
    "            'next_fold': fold + 1,\n",
    "            'data_len': len(train_full),\n",
    "            'complete': False,\n",
    "        }\n",
    "        with open(CKPT_PATH, 'wb') as f:\n",
    "            pickle.dump(ckpt_data, f)\n",
    "        print(f\"    체크포인트 저장 완료 (Fold {fold+1}/{N_FOLDS})\")\n",
    "\n",
    "        del mdl, fgm_obj, ema_obj, best_st\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    all_oof_probs = [m_oof]\n",
    "\n",
    "    # 최종 체크포인트 저장\n",
    "    ckpt_final = {\n",
    "        'all_model_probs': all_model_probs,\n",
    "        'all_fold_results': all_fold_results,\n",
    "        'all_oof_probs': all_oof_probs,\n",
    "        'oof_labels': oof_labels,\n",
    "        'complete': True,\n",
    "    }\n",
    "    with open(CKPT_PATH, 'wb') as f:\n",
    "        pickle.dump(ckpt_final, f)\n",
    "\n",
    "    total_min = (time.time() - t_start) / 60\n",
    "    print(f\"\\n총 학습 시간: {total_min:.1f}분\")\n",
    "\n",
    "print(f\"\\n학습 완료! {len(all_fold_results)} fold 결과\")\n",
    "for r in all_fold_results:\n",
    "    print(f\"  {r['model']} Fold {r['fold']}: Val F1 = {r['best_val_f1']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "  Ensemble + Calibration + Threshold\n",
      "============================================================\n",
      "  KLUE-BERT-TAPT F1: 0.9264\n",
      "  KLUE-BERT-TAPT F2: 0.9308\n",
      "  KLUE-BERT-TAPT F3: 0.9389\n",
      "  KLUE-BERT-TAPT F4: 0.9357\n",
      "  KLUE-BERT-TAPT F5: 0.9352\n",
      "\n",
      "  평균 Val F1: 0.9334\n",
      "\n",
      "  [보정 전]:\n",
      "    협박 대화: 98\n",
      "    갈취 대화: 113\n",
      "    직장 내 괴롭힘 대화: 120\n",
      "    기타 괴롭힘 대화: 145\n",
      "    일반 대화: 24\n",
      "\n",
      "  [보정 후]:\n",
      "    협박 대화: 105\n",
      "    갈취 대화: 109\n",
      "    직장 내 괴롭힘 대화: 114\n",
      "    기타 괴롭힘 대화: 153\n",
      "    일반 대화: 19\n",
      "\n",
      "  Threshold 최적화:\n",
      "  기본 OOF F1: 0.9320\n",
      "  최적화 후 OOF F1: 0.9335\n",
      "  Thresholds: ['0.60', '1.65', '1.00', '1.00', '1.00']\n",
      "\n",
      "  [최종]:\n",
      "    협박 대화: 95\n",
      "    갈취 대화: 115\n",
      "    직장 내 괴롭힘 대화: 114\n",
      "    기타 괴롭힘 대화: 156\n",
      "    일반 대화: 20\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# STEP 7: Ensemble + Prior Calibration + Threshold\n",
    "# ============================================================\n",
    "# 변수 안전 확인 (런타임 끊김 복구)\n",
    "try:\n",
    "    _ = all_fold_results\n",
    "    _ = all_model_probs\n",
    "except NameError:\n",
    "    CKPT_PATH = os.path.join(CKPT_DIR, 'v7_checkpoint.pkl')\n",
    "    if os.path.exists(CKPT_PATH):\n",
    "        with open(CKPT_PATH, 'rb') as f:\n",
    "            ckpt = pickle.load(f)\n",
    "        all_model_probs = ckpt['all_model_probs']\n",
    "        all_fold_results = ckpt['all_fold_results']\n",
    "        all_oof_probs = ckpt.get('all_oof_probs', [ckpt.get('m_oof')])\n",
    "        oof_labels = ckpt.get('oof_labels', train_full['label'].values.copy())\n",
    "        print(\"[복구] 체크포인트에서 학습 결과 로드 완료!\")\n",
    "    else:\n",
    "        raise RuntimeError(\"학습 결과 없음! Cell 13을 먼저 실행하세요.\")\n",
    "\n",
    "try:\n",
    "    _ = train_prior\n",
    "    _ = test_prior\n",
    "except NameError:\n",
    "    tp_path = os.path.join(CKPT_DIR, 'train_prior.npy')\n",
    "    if os.path.exists(tp_path):\n",
    "        train_prior = np.load(tp_path)\n",
    "        test_prior = np.load(os.path.join(CKPT_DIR, 'test_prior.npy'))\n",
    "        cal_ratio = np.load(os.path.join(CKPT_DIR, 'cal_ratio.npy'))\n",
    "        print(\"[복구] prior 데이터 로드 완료!\")\n",
    "    else:\n",
    "        raise RuntimeError(\"prior 데이터 없음! Cell 9를 먼저 실행하세요.\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"  Ensemble + Calibration + Threshold\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "for r in all_fold_results:\n",
    "    print(f\"  {r['model']} F{r['fold']}: {r['best_val_f1']:.4f}\")\n",
    "avg_val_f1 = np.mean([r['best_val_f1'] for r in all_fold_results])\n",
    "print(f\"\\n  평균 Val F1: {avg_val_f1:.4f}\")\n",
    "\n",
    "# Weighted ensemble\n",
    "wts = np.array([r['best_val_f1'] for r in all_fold_results])\n",
    "wts = wts / wts.sum()\n",
    "ens_test = sum(w * p for w, p in zip(wts, all_model_probs))\n",
    "ens_oof = np.mean(all_oof_probs, axis=0)\n",
    "\n",
    "raw_preds = np.argmax(ens_test, 1)\n",
    "print(f\"\\n  [보정 전]:\")\n",
    "for i, c in sorted(Counter(raw_preds).items()):\n",
    "    print(f\"    {IDX2CLASS[i]}: {c}\")\n",
    "\n",
    "# Calibration\n",
    "cal_test = calibrate_probs(ens_test, train_prior, test_prior)\n",
    "cal_oof = calibrate_probs(ens_oof, train_prior, test_prior)\n",
    "\n",
    "cal_preds = np.argmax(cal_test, 1)\n",
    "print(f\"\\n  [보정 후]:\")\n",
    "for i, c in sorted(Counter(cal_preds).items()):\n",
    "    print(f\"    {IDX2CLASS[i]}: {c}\")\n",
    "\n",
    "# Threshold optimization\n",
    "print(f\"\\n  Threshold 최적화:\")\n",
    "thresholds = optimize_thresholds(cal_oof, oof_labels)\n",
    "\n",
    "adj_test = cal_test.copy()\n",
    "for cls in range(NUM_CLASSES):\n",
    "    adj_test[:, cls] *= thresholds[cls]\n",
    "ens_preds = np.argmax(adj_test, 1)\n",
    "print(f\"\\n  [최종]:\")\n",
    "for i, c in sorted(Counter(ens_preds).items()):\n",
    "    print(f\"    {IDX2CLASS[i]}: {c}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "  Hard Sample Mining + Pseudo Labeling\n",
      "============================================================\n",
      "  고확신 (>=0.95): 154개 -> Pseudo Label\n",
      "  중간 확신 (0.5~0.95): 312개 -> Hard Sample (2x)\n",
      "  저확신 (<0.5): 34개 -> 제외\n",
      "  train + pseudo + hard(2x): 27051개\n",
      "    Pseudo 갈취 대화: 99\n",
      "    Pseudo 직장 내 괴롭힘 대화: 30\n",
      "    Pseudo 기타 괴롭힘 대화: 19\n",
      "    Pseudo 일반 대화: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|██████████| 197/197 [00:00<00:00, 1036.58it/s, Materializing param=bert.encoder.layer.11.output.dense.weight]             \n",
      "\u001b[1mBertForSequenceClassification LOAD REPORT\u001b[0m from: /home/ubuntu/lambda-fs/v7_ckpts/tapt_model\n",
      "Key                                        | Status     | \n",
      "-------------------------------------------+------------+-\n",
      "cls.predictions.transform.dense.weight     | UNEXPECTED | \n",
      "cls.predictions.transform.LayerNorm.weight | UNEXPECTED | \n",
      "cls.predictions.transform.LayerNorm.bias   | UNEXPECTED | \n",
      "cls.predictions.transform.dense.bias       | UNEXPECTED | \n",
      "cls.predictions.bias                       | UNEXPECTED | \n",
      "bert.pooler.dense.bias                     | MISSING    | \n",
      "bert.pooler.dense.weight                   | MISSING    | \n",
      "classifier.bias                            | MISSING    | \n",
      "classifier.weight                          | MISSING    | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
      "- MISSING\u001b[3m\t:those params were newly initialized because missing from the checkpoint. Consider training on your downstream task.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Pseudo Ep 1/5 | Train F1: 0.6945 | Val F1: 0.8897  *\n",
      "    Pseudo Ep 2/5 | Train F1: 0.9229 | Val F1: 0.9356  *\n",
      "    Pseudo Ep 3/5 | Train F1: 0.9581 | Val F1: 0.9417  *\n",
      "    Pseudo Ep 4/5 | Train F1: 0.9783 | Val F1: 0.9450  *\n",
      "    Pseudo Ep 5/5 | Train F1: 0.9890 | Val F1: 0.9465  *\n",
      "    >> Best Pseudo Val F1: 0.9465\n",
      "\n",
      "  Confidence Fallback: 19개 -> 일반 대화\n",
      "[pseudo checkpoint saved]\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# STEP 8: Hard Sample Mining + Pseudo Labeling (체크포인트 지원)\n",
    "# ============================================================\n",
    "PSEUDO_CKPT_PATH = os.path.join(CKPT_DIR, 'pseudo_done.pkl')\n",
    "\n",
    "if os.path.exists(PSEUDO_CKPT_PATH):\n",
    "    print(\"[체크포인트] Pseudo labeling 결과 로드\")\n",
    "    with open(PSEUDO_CKPT_PATH, 'rb') as f:\n",
    "        pseudo_ckpt = pickle.load(f)\n",
    "    final_probs = pseudo_ckpt['final_probs']\n",
    "    final_preds = pseudo_ckpt['final_preds']\n",
    "else:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"  Hard Sample Mining + Pseudo Labeling\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    max_probs = np.max(adj_test, 1)\n",
    "    confident_mask = max_probs >= PSEUDO_THRESHOLD\n",
    "    pseudo_labels = ens_preds[confident_mask]\n",
    "\n",
    "    medium_mask = (max_probs >= 0.5) & (max_probs < PSEUDO_THRESHOLD)\n",
    "\n",
    "    print(f\"  고확신 (>={PSEUDO_THRESHOLD}): {confident_mask.sum()}개 -> Pseudo Label\")\n",
    "    print(f\"  중간 확신 (0.5~{PSEUDO_THRESHOLD}): {medium_mask.sum()}개 -> Hard Sample (2x)\")\n",
    "    print(f\"  저확신 (<0.5): {(~confident_mask & ~medium_mask).sum()}개 -> 제외\")\n",
    "\n",
    "    if confident_mask.sum() > 50:\n",
    "        pseudo_df = pd.DataFrame({\n",
    "            'idx': test_df[confident_mask]['idx'].values,\n",
    "            'class': [IDX2CLASS[l] for l in pseudo_labels],\n",
    "            'conversation': test_df[confident_mask]['conversation'].values,\n",
    "            'label': pseudo_labels\n",
    "        })\n",
    "\n",
    "        hard_labels = ens_preds[medium_mask]\n",
    "        hard_df = pd.DataFrame({\n",
    "            'idx': test_df[medium_mask]['idx'].values,\n",
    "            'class': [IDX2CLASS[l] for l in hard_labels],\n",
    "            'conversation': test_df[medium_mask]['conversation'].values,\n",
    "            'label': hard_labels\n",
    "        })\n",
    "\n",
    "        train_pseudo = pd.concat([train_full, pseudo_df, hard_df, hard_df],\n",
    "                                 ignore_index=True)\n",
    "        print(f\"  train + pseudo + hard(2x): {len(train_pseudo)}개\")\n",
    "\n",
    "        for i, c in sorted(Counter(pseudo_labels).items()):\n",
    "            print(f\"    Pseudo {IDX2CLASS[i]}: {c}\")\n",
    "\n",
    "        tok_p = AutoTokenizer.from_pretrained(MODEL_CONFIGS[0]['name'])\n",
    "        pt, pv = train_test_split(\n",
    "            train_pseudo, test_size=0.1,\n",
    "            stratify=train_pseudo['label'], random_state=SEED)\n",
    "        ptds = DKTCDataset(pt['conversation'].values, pt['label'].values, tok_p, MAX_LEN)\n",
    "        pvds = DKTCDataset(pv['conversation'].values, pv['label'].values, tok_p, MAX_LEN)\n",
    "        ptdl = DataLoader(ptds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "        pvdl = DataLoader(pvds, batch_size=BATCH_SIZE)\n",
    "\n",
    "        plc = pt['label'].value_counts().sort_index()\n",
    "        pcw = torch.tensor([len(pt) / (NUM_CLASSES * c) for c in plc.values],\n",
    "                           dtype=torch.float32).to(DEVICE)\n",
    "        twb = torch.tensor(cal_ratio, dtype=torch.float32).to(DEVICE)\n",
    "        pcw = pcw * (twb ** 0.3)\n",
    "        pcw = pcw / pcw.mean()\n",
    "\n",
    "        plf = FocalLoss(alpha=pcw, gamma=2.0,\n",
    "                        label_smoothing=LABEL_SMOOTHING).to(DEVICE)\n",
    "        pm = AutoModelForSequenceClassification.from_pretrained(\n",
    "            MODEL_CONFIGS[0]['name'], num_labels=NUM_CLASSES).to(DEVICE)\n",
    "        po = get_llrd_optimizer(pm, LR, WEIGHT_DECAY, LLRD_FACTOR)\n",
    "        ps = len(ptdl) * EPOCHS\n",
    "        psc = get_linear_schedule_with_warmup(po, int(ps * WARMUP_RATIO), ps)\n",
    "        pf = FGM(pm, FGM_EPSILON)\n",
    "        pe = EMA(pm, EMA_DECAY)\n",
    "\n",
    "        bf1, bst = 0, None\n",
    "        for ep in range(EPOCHS):\n",
    "            tl, ta, tf = train_one_epoch(pm, ptdl, po, psc, plf, pf, pe, True)\n",
    "            pe.apply_shadow()\n",
    "            vl, va, vf, _, _ = evaluate(pm, pvdl, plf)\n",
    "            if vf > bf1:\n",
    "                bf1 = vf\n",
    "                bst = {k: v.cpu().clone() for k, v in pm.state_dict().items()}\n",
    "            pe.restore()\n",
    "            print(f\"    Pseudo Ep {ep+1}/{EPOCHS} | Train F1: {tf:.4f} | \"\n",
    "                  f\"Val F1: {vf:.4f}{'  *' if vf >= bf1 else ''}\")\n",
    "\n",
    "        print(f\"    >> Best Pseudo Val F1: {bf1:.4f}\")\n",
    "        pm.load_state_dict(bst)\n",
    "        pm.to(DEVICE)\n",
    "        tds = DKTCDataset(test_df['conversation'].values, None, tok_p, MAX_LEN)\n",
    "        tdl = DataLoader(tds, batch_size=BATCH_SIZE)\n",
    "        pp = predict_proba(pm, tdl)\n",
    "        pp_cal = calibrate_probs(pp, train_prior, test_prior)\n",
    "\n",
    "        final_probs = 0.4 * cal_test + 0.6 * pp_cal\n",
    "        for cls in range(NUM_CLASSES):\n",
    "            final_probs[:, cls] *= thresholds[cls]\n",
    "        final_preds = np.argmax(final_probs, 1)\n",
    "\n",
    "        del pm, pf, pe, bst\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "    else:\n",
    "        print(\"  고확신 부족 -> Pseudo Labeling 건너뜀\")\n",
    "        final_probs = adj_test.copy()\n",
    "        final_preds = ens_preds.copy()\n",
    "\n",
    "    # Confidence fallback\n",
    "    dmax = np.max(final_probs[:, :4], 1)\n",
    "    low = dmax < 0.15\n",
    "    if low.sum() > 0:\n",
    "        print(f\"\\n  Confidence Fallback: {low.sum()}개 -> 일반 대화\")\n",
    "        final_preds[low] = 4\n",
    "\n",
    "    # 체크포인트 저장\n",
    "    with open(PSEUDO_CKPT_PATH, 'wb') as f:\n",
    "        pickle.dump({'final_probs': final_probs, 'final_preds': final_preds}, f)\n",
    "    print(\"[pseudo checkpoint saved]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submission_v7.csv 저장 완료!\n",
      "\n",
      "최종 예측 분포:\n",
      "  협박 대화: 92개\n",
      "  갈취 대화: 116개\n",
      "  직장 내 괴롭힘 대화: 115개\n",
      "  기타 괴롭힘 대화: 155개\n",
      "  일반 대화: 22개\n",
      "\n",
      "일반 대화: 22개 (4.4%)\n",
      "\n",
      "예상 vs 실제:\n",
      "  협박 대화: 예상 39 | 실제 92 | 차이 +53\n",
      "  갈취 대화: 예상 23 | 실제 116 | 차이 +93\n",
      "  직장 내 괴롭힘 대화: 예상 21 | 실제 115 | 차이 +94\n",
      "  기타 괴롭힘 대화: 예상 39 | 실제 155 | 차이 +116\n",
      "  일반 대화: 예상 378 | 실제 22 | 차이 -356\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# STEP 9: 제출파일 생성\n",
    "# ============================================================\n",
    "submission_df['class'] = final_preds.astype(int)\n",
    "submission_df.to_csv('submission_v7.csv', index=False)\n",
    "\n",
    "print(\"submission_v7.csv 저장 완료!\")\n",
    "print(f\"\\n최종 예측 분포:\")\n",
    "fc = Counter(final_preds)\n",
    "for i in sorted(fc.keys()):\n",
    "    print(f\"  {IDX2CLASS[i]}: {fc[i]}개\")\n",
    "\n",
    "nc = sum(1 for p in final_preds if p == 4)\n",
    "print(f\"\\n일반 대화: {nc}개 ({nc/len(final_preds)*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\n예상 vs 실제:\")\n",
    "for i in range(NUM_CLASSES):\n",
    "    e, a = EST_TEST_DIST[i], fc.get(i, 0)\n",
    "    print(f\"  {IDX2CLASS[i]}: 예상 {e} | 실제 {a} | 차이 {a-e:+d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1800x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================================\n",
    "# STEP 10: 결과 시각화\n",
    "# ============================================================\n",
    "try:\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "    ax = axes[0]\n",
    "    for mc in MODEL_CONFIGS:\n",
    "        ms = mc['short']\n",
    "        ff = [r['best_val_f1'] for r in all_fold_results if r['model'] == ms]\n",
    "        ax.bar([f\"{ms}\\nF{i+1}\" for i in range(len(ff))], ff, alpha=0.7, label=ms)\n",
    "    ax.set_ylabel('Val F1')\n",
    "    ax.set_title('K-Fold Val F1')\n",
    "    ax.legend()\n",
    "    ax.set_ylim(0.85, 1.0)\n",
    "\n",
    "    ax = axes[1]\n",
    "    ln = [IDX2CLASS[i] for i in range(NUM_CLASSES)]\n",
    "    x = np.arange(NUM_CLASSES)\n",
    "    rv = [Counter(raw_preds).get(i, 0) for i in range(NUM_CLASSES)]\n",
    "    fv = [fc.get(i, 0) for i in range(NUM_CLASSES)]\n",
    "    w = 0.35\n",
    "    ax.bar(x - w/2, rv, w, label='보정 전', alpha=0.7)\n",
    "    ax.bar(x + w/2, fv, w, label='보정 후 (v7)', alpha=0.7)\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(ln, rotation=45, ha='right')\n",
    "    ax.set_title('보정 전 vs 보정 후')\n",
    "    ax.legend()\n",
    "\n",
    "    ax = axes[2]\n",
    "    ev = [EST_TEST_DIST[i] for i in range(NUM_CLASSES)]\n",
    "    ax.barh(ln, fv, alpha=0.7, label='v7 예측')\n",
    "    ax.barh(ln, ev, alpha=0.3, label='예상',\n",
    "            edgecolor='red', linewidth=2, fill=False)\n",
    "    ax.set_title('최종 vs 예상')\n",
    "    ax.legend()\n",
    "    for i, v in enumerate(fv):\n",
    "        ax.text(v + 2, i, str(v), va='center')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('v7_results.png', dpi=150)\n",
    "    plt.show()\n",
    "except Exception as e:\n",
    "    print(f\"시각화 오류: {e}\")\n",
    "    print(\"시각화 건너뜀\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "  DKTC v7 프로젝트 정리\n",
      "============================================================\n",
      "\n",
      "  [v7-1] TAPT: klue/bert-base + MLM 사전학습 (5ep)\n",
      "  [v7-2] 대규모 일반대화: korean_safe_conversation + KOTE + 기존 소스\n",
      "  [v7-3] 모델: klue/bert-base (0.882 달성 참고)\n",
      "\n",
      "  [v3] K-Fold(5F) + R-Drop + Focal Loss\n",
      "  [v4] LLRD=0.95, FGM=1.0, EMA=0.999, LS=0.05\n",
      "  [v5] Prior Calibration, Confidence Fallback\n",
      "  [v6] Hard Negative 200개, Hard Sample Mining, Dynamic Class Weight\n",
      "\n",
      "  평균 Val F1: 0.9334\n",
      "  제출파일: submission_v7.csv\n",
      "\n",
      "  참고:\n",
      "  - https://ratsgo.github.io/embedding/downloaddata.html\n",
      "  - https://github.com/sda96/AIFFEL_3rd_hackerton_TUNiB_DKTC\n",
      "\n",
      "  완료!\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"  DKTC v7 프로젝트 정리\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\n  [v7-1] TAPT: klue/bert-base + MLM 사전학습 ({TAPT_EPOCHS}ep)\")\n",
    "print(f\"  [v7-2] 대규모 일반대화: korean_safe_conversation + KOTE + 기존 소스\")\n",
    "print(f\"  [v7-3] 모델: {BASE_MODEL} (0.882 달성 참고)\")\n",
    "print(f\"\\n  [v3] K-Fold({N_FOLDS}F) + R-Drop + Focal Loss\")\n",
    "print(f\"  [v4] LLRD={LLRD_FACTOR}, FGM={FGM_EPSILON}, EMA={EMA_DECAY}, LS={LABEL_SMOOTHING}\")\n",
    "print(f\"  [v5] Prior Calibration, Confidence Fallback\")\n",
    "print(f\"  [v6] Hard Negative 200개, Hard Sample Mining, Dynamic Class Weight\")\n",
    "try:\n",
    "    _avg = np.mean([r['best_val_f1'] for r in all_fold_results])\n",
    "    print(f\"\\n  평균 Val F1: {_avg:.4f}\")\n",
    "except Exception:\n",
    "    pass\n",
    "print(f\"  제출파일: submission_v7.csv\")\n",
    "print(f\"\\n  참고:\")\n",
    "print(f\"  - https://ratsgo.github.io/embedding/downloaddata.html\")\n",
    "print(f\"  - https://github.com/sda96/AIFFEL_3rd_hackerton_TUNiB_DKTC\")\n",
    "print(f\"\\n  완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "제출파일 위치: /home/william/jupyterlab-home/submission_v7.csv\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/william/jupyterlab-home/submission_v7.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m output_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/william/jupyterlab-home/submission_v7.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m제출파일 위치: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m파일 크기: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetsize\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m bytes\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/lib/python3.12/genericpath.py:62\u001b[0m, in \u001b[0;36mgetsize\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgetsize\u001b[39m(filename):\n\u001b[1;32m     61\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the size of a file, reported by os.stat().\"\"\"\u001b[39;00m\n\u001b[0;32m---> 62\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mst_size\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/william/jupyterlab-home/submission_v7.csv'"
     ]
    }
   ],
   "source": [
    "output_path = '/home/william/jupyterlab-home/submission_v7.csv'\n",
    "print(f\"제출파일 위치: {output_path}\")\n",
    "print(f\"파일 크기: {os.path.getsize(output_path):,} bytes\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
