{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# DKTC (Dangerous Talk Classification)\n## AIFFEL DLthon - 한국어 위협 대화 5클래스 분류\n\n---\n\n### 전략: 가브리엘 페터슨 탑다운 접근법\n\n| Level | 전략 | 이 코드에서 해당하는 부분 |\n|-------|------|--------------------------|\n| **Level 1** | 베이스라인 → 문제 발견 | STEP 0~1: EDA로 \"일반대화 0개\" 문제 발견, STEP 5 Exp1: CE Loss baseline |\n| **Level 2** | 최신 논문 기법으로 해결 | STEP 2: 합성데이터(AugGPT 영감), STEP 4: Focal Loss + R-Drop, STEP 5 Exp2~3 |\n| **Level 3** | Ablation Study로 정량 검증 | STEP 5 Exp1~4 비교, STEP 6: 시각화로 기여도 증명 |\n\n### 코드 구조 요약\n\n| STEP | 내용 | 배운 것 / 최신 기법 |\n|------|------|---------------------|\n| 0 | 환경 설정, GPU 확인 | - |\n| 1 | EDA - 클래스 분포, 길이 분석 | Ex06 (네이버 영화리뷰 감성분석) |\n| 2 | 일반대화 합성데이터 5개 소스 | AugGPT (Dai et al., 2023) 논문 영감 |\n| 3 | 텍스트 전처리 | Ex06 전처리, Ex07 (SentencePiece 토큰화) |\n| 4 | KcELECTRA + Focal Loss + R-Drop 정의 | Ex09 (Transformer), ELECTRA/Lin 2017/Liang 2021 논문 |\n| 5 | Ablation 4개 실험 실행 | Ex03 (Ablation Study 설계 방법론) |\n| 6 | 시각화 (학습곡선, Confusion Matrix) | Ex03 시각화 |\n| 7 | 테스트 예측 → submission.csv | - |\n| 8 | 프로젝트 정리 | 발표 포인트 |\n\n### 클래스 매핑\n\n| 라벨 | 클래스 |\n|------|--------|\n| 0 | 협박 대화 |\n| 1 | 갈취 대화 |\n| 2 | 직장 내 괴롭힘 대화 |\n| 3 | 기타 괴롭힘 대화 |\n| 4 | 일반 대화 (train에 0개 → 합성 필요!) |"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## STEP 0: 환경 설정 및 설치\n> **Level 1 (베이스라인 준비)** — 실험에 필요한 라이브러리 설치 및 외부 데이터 다운로드"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# STEP 0-1: 라이브러리 설치 + 합성데이터 소스 미리 다운로드\n# ============================================================\n# transformers: HuggingFace 모델/토크나이저 (KcELECTRA 로드용)\n# datasets: HuggingFace 데이터셋 (kor_unsmile, NSMC 다운로드용)\n# accelerate: HuggingFace 모델 최적화 (transformers 내부 의존성)\n!pip install -q transformers datasets accelerate scikit-learn matplotlib seaborn pandas\n\n# [Level 2] 합성데이터 소스 미리 다운로드 (STEP 2에서 사용)\n# → AugGPT(Dai et al., 2023) 논문에서 영감: \"학습데이터 부족 시 외부 소스로 증강\"\n# SmileStyle: 스마일게이트 AI가 공개한 한국어 17가지 스타일 대화 데이터셋\n!wget -q https://raw.githubusercontent.com/smilegate-ai/korean_smile_style_dataset/main/smilestyle_dataset.tsv -O smilestyle_dataset.tsv\n# KakaoChatData: 실제 카카오톡 대화 스타일 챗봇 데이터 (~73K쌍)\n!wget -q https://raw.githubusercontent.com/Ludobico/KakaoChatData/main/Dataset/ChatbotData.csv -O ChatbotData.csv\n\nprint(\"설치 완료!\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# STEP 0-2: import + 시드 고정 + GPU 확인\n# ============================================================\nimport os\nimport random\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader          # Ex06에서 배운 Dataset/DataLoader 패턴\nfrom transformers import (\n    AutoTokenizer, AutoModelForSequenceClassification,     # HuggingFace 모델 로드 (Ex09 Transformer 활용)\n    get_linear_schedule_with_warmup                        # 학습률 스케줄러: warmup 후 선형 감소\n)\nfrom sklearn.model_selection import train_test_split       # stratified 분할 (클래스 비율 유지)\nfrom sklearn.metrics import (\n    accuracy_score, f1_score, classification_report, confusion_matrix  # Ex03 Ablation 평가 지표\n)\nfrom datasets import load_dataset                          # HuggingFace Hub에서 데이터 다운로드\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom collections import Counter\nimport warnings\nwarnings.filterwarnings('ignore')\n\nplt.rcParams['font.family'] = 'DejaVu Sans'  # Colab 한글 깨짐 방지\n\n# ──────────────────────────────────────────────\n# 재현성(reproducibility) 보장을 위한 시드 고정\n# → 같은 시드면 같은 결과가 나옴 → Ablation 비교가 공정해짐\n# ──────────────────────────────────────────────\nSEED = 42\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\ntorch.cuda.manual_seed_all(SEED)\ntorch.backends.cudnn.deterministic = True  # GPU 연산도 결정론적으로\n\nDEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Device: {DEVICE}\")\nif torch.cuda.is_available():\n    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# STEP 0-3: 클래스 매핑 + 하이퍼파라미터 설정\n# ============================================================\n\n# 5개 클래스 정의 (대회 제출 형식: 정수 0~4)\nCLASS_NAMES = ['협박 대화', '갈취 대화', '직장 내 괴롭힘 대화', '기타 괴롭힘 대화', '일반 대화']\nCLASS2IDX = {name: idx for idx, name in enumerate(CLASS_NAMES)}  # \"협박 대화\" → 0\nIDX2CLASS = {idx: name for idx, name in enumerate(CLASS_NAMES)}  # 0 → \"협박 대화\"\nNUM_CLASSES = 5\n\n# ──────────────────────────────────────────────\n# 하이퍼파라미터\n# ──────────────────────────────────────────────\n# [Level 2] 모델 선택 근거:\n#   KcELECTRA(beomi) = ELECTRA(Clark et al., 2020) 구조를 한국어 댓글/구어체로 사전학습\n#   → DKTC 데이터가 반말+구어체이므로 도메인이 일치\n#   → 일반 BERT/KoBERT보다 이런 비격식 텍스트에서 성능 우수\nMODEL_NAME = 'beomi/KcELECTRA-base-v2022'\n\nMAX_LEN = 256       # 토큰 최대 길이 (STEP 3에서 95%ile 확인 후 결정)\nBATCH_SIZE = 16      # GPU 메모리에 맞춤 (T4 기준)\nEPOCHS = 5           # 시간 부족 시 3으로 줄여도 됨\nLR = 2e-5            # Pre-trained 모델 fine-tuning 표준 학습률\nWEIGHT_DECAY = 0.01  # AdamW 정규화 (과적합 방지)\nWARMUP_RATIO = 0.1   # 전체 스텝의 10%는 학습률을 서서히 올림 (안정적 시작)\nMAX_GRAD_NORM = 1.0  # Gradient Clipping (기울기 폭발 방지)\nVAL_RATIO = 0.15     # 15% 검증셋 (stratified로 클래스 비율 유지)\n\nprint(\"설정 완료\")\nprint(f\"모델: {MODEL_NAME}\")\nprint(f\"EPOCHS: {EPOCHS}, LR: {LR}, MAX_LEN: {MAX_LEN}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## STEP 1: 데이터 로드 및 EDA\n> **Level 1 (베이스라인 → 문제 발견)** — Ex06(네이버 영화리뷰 감성분석)에서 배운 EDA 패턴 적용\n>\n> 여기서 **핵심 문제를 발견**: train에 \"일반 대화\" 클래스가 **0개**!\n> → test에는 ~100개 있을 것으로 추정 → 이걸 해결 안 하면 일반대화를 절대 맞출 수 없음"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# STEP 1-1: 데이터 로드\n# [Level 1] 가장 먼저 할 일: 데이터를 눈으로 확인하기\n# ============================================================\n# ⚠️ train.csv, test.csv, submission.csv를 Colab에 업로드하세요!\n# 방법 1: 왼쪽 파일 탭에서 드래그 앤 드롭\n# 방법 2: 아래 코드 실행\n# from google.colab import files\n# uploaded = files.upload()\n\ntrain_df = pd.read_csv('train.csv')      # 3,950개, 4개 클래스만 존재\ntest_df = pd.read_csv('test.csv')        # 500개, 5개 클래스 (일반대화 포함)\nsubmission_df = pd.read_csv('submission.csv')  # idx + class(예측값 넣을 곳)\n\nprint(f\"Train: {len(train_df)}개\")\nprint(f\"Test:  {len(test_df)}개\")\nprint(f\"\\n컬럼: {list(train_df.columns)}\")\n# ⭐ 여기서 핵심 문제 발견: '일반 대화'가 없다!\nprint(f\"\\n클래스 분포:\")\nprint(train_df['class'].value_counts())"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# STEP 1-2: EDA 시각화\n# [Level 1] Ex06에서 배운 데이터 탐색 패턴\n# → 클래스 분포, 텍스트 길이, 클래스별 길이 차이를 시각화\n# → 이 단계에서 \"일반 대화 0개\" 문제를 눈으로 확인\n# ============================================================\nfig, axes = plt.subplots(1, 3, figsize=(18, 5))\n\n# 1) 클래스 분포 → ⭐ \"일반 대화\"가 아예 없음을 확인!\nclass_counts = train_df['class'].value_counts()\naxes[0].barh(class_counts.index, class_counts.values, color='steelblue')\naxes[0].set_title('Class Distribution (Train)')\naxes[0].set_xlabel('Count')\nfor i, v in enumerate(class_counts.values):\n    axes[0].text(v + 10, i, str(v), va='center')  # 막대 끝에 숫자 표시\n\n# 2) 대화 길이 분포 → MAX_LEN 결정에 참고\ntrain_df['text_len'] = train_df['conversation'].str.len()\naxes[1].hist(train_df['text_len'], bins=50, color='coral', edgecolor='white')\naxes[1].set_title('Conversation Length Distribution')\naxes[1].set_xlabel('Characters')\naxes[1].axvline(train_df['text_len'].mean(), color='red', linestyle='--',\n                label=f\"Mean: {train_df['text_len'].mean():.0f}\")\naxes[1].legend()\n\n# 3) 클래스별 길이 분포 → 클래스 간 길이 차이가 있는지 확인\nfor cls_name in train_df['class'].unique():\n    subset = train_df[train_df['class'] == cls_name]['text_len']\n    axes[2].hist(subset, bins=30, alpha=0.5, label=cls_name)\naxes[2].set_title('Length by Class')\naxes[2].set_xlabel('Characters')\naxes[2].legend(fontsize=8)\n\nplt.tight_layout()\nplt.show()\n\nprint(f\"\\n대화 길이 통계:\")\nprint(train_df['text_len'].describe())\n# ⭐ Level 1 핵심 발견: 이 문제를 Level 2에서 합성데이터로 해결\nprint(f\"\\n⚠️ '일반 대화' 클래스가 train에 없음! → 합성 데이터 필요\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## STEP 2: 합성 일반대화 수집 (5개 소스)\n> **Level 2 (최신 논문 기법으로 문제 해결)** — AugGPT(Dai et al., 2023) 논문에서 영감\n>\n> **문제**: train에 일반대화가 0개 → 모델이 \"일반 대화\"를 전혀 학습할 수 없음\n>\n> **해결**: 외부 공개 데이터에서 일반대화를 수집하여 합성\n> - 논문 근거: AugGPT는 \"소규모 데이터를 LLM으로 증강\"하는 기법을 제안\n> - 우리는 LLM 대신 **공개 데이터셋 5개를 조합**하여 다양성 확보\n> - 단일 소스가 아닌 **다중 소스**로 편향(bias)을 줄임\n\n| # | 소스 | 왜 이 소스를 선택했나 | 목표 수 |\n|---|------|----------------------|---------|\n| 1 | SmileStyle | 17가지 스타일 중 informal(반말) = DKTC 대화체와 가장 유사 | 400 |\n| 2 | KakaoChatData | 실제 카톡 대화 → 가장 자연스러운 구어체 | 300 |\n| 3 | kor_unsmile | 혐오표현 데이터에서 clean=1(비혐오)만 추출 → \"위험하지 않은\" 문장 | 200 |\n| 4 | NSMC | 긍정 영화리뷰 → 무해한 일상 감정 표현 | 100 |\n| 5 | **경계 케이스** ⭐ | \"야 죽을래 ㅋㅋ\" 같은 농담 → **핵심 차별화 포인트** | 25 |"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# STEP 2-0: 위협 키워드 필터 정의\n# [Level 2] 합성데이터 품질 관리\n# → 외부 데이터에서 수집할 때, 실제 위협 문장이 섞이면 라벨 오류 발생\n# → 키워드 기반 필터로 위협성 문장을 사전에 제거\n# ============================================================\n\n# 4개 위협 클래스의 핵심 키워드를 수집\n# 협박: 물리적 위협 (\"죽여\", \"찔러\")\n# 갈취: 금전 요구 (\"돈 내놔\", \"빚\")\n# 직장 괴롭힘: 조직 관련 (\"해고\", \"사직서\")\n# 기타 괴롭힘: 사회적 따돌림 (\"따돌\", \"왕따\")\nTHREAT_KEYWORDS = [\n    '죽여', '죽일', '찔러', '칼로', '패줄', '두들겨', '불질러',     # 협박\n    '협박', '신고', '경찰', '감옥', '고소', '소송',                   # 협박/법적 위협\n    '돈 내놔', '송금', '이자', '빚', '갚아',                          # 갈취\n    '해고', '짤리', '사직서', '퇴사', '상사',                         # 직장 괴롭힘\n    '따돌', '왕따', '무시', '괴롭'                                    # 기타 괴롭힘\n]\n\ndef contains_threat(text):\n    \"\"\"텍스트에 위협 키워드가 하나라도 포함되면 True 반환\"\"\"\n    return any(kw in str(text) for kw in THREAT_KEYWORDS)\n\nnormal_samples = []  # 모든 소스에서 수집한 일반대화를 여기에 모음"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# STEP 2-1: 소스 1 - SmileStyle (목표 400개)\n# [Level 2] 스마일게이트 AI 공개 데이터셋\n# 선택 이유: 17가지 한국어 스타일 중 informal(반말) 컬럼이\n#           DKTC 대화 데이터의 구어체/반말 스타일과 가장 유사\n# 처리 방법: 단문 3개를 이어 붙여 멀티턴 대화처럼 구성\n#           (DKTC train 평균 ~220자에 맞추기 위해)\n# ============================================================\nprint(\"=\"*50)\nprint(\"소스 1: SmileStyle 한국어 멀티턴 대화\")\nprint(\"=\"*50)\n\ntry:\n    smile_df = pd.read_csv('smilestyle_dataset.tsv', sep='\\t')\n    print(f\"전체 데이터: {len(smile_df)}개\")\n    print(f\"컬럼: {list(smile_df.columns)}\")\n\n    # informal/chat/반말/casual 키워드가 포함된 컬럼 찾기\n    # → 이 컬럼이 DKTC의 반말 대화체와 가장 유사\n    target_cols = []\n    for col in smile_df.columns:\n        if any(kw in col.lower() for kw in ['informal', 'chat', '반말', 'casual']):\n            target_cols.append(col)\n\n    if not target_cols:\n        print(f\"  → informal 컬럼 못찾음, 전체 컬럼: {list(smile_df.columns)}\")\n        target_cols = [smile_df.columns[-1]]\n\n    print(f\"  사용 컬럼: {target_cols}\")\n\n    smile_texts = []\n    for col in target_cols:\n        texts = smile_df[col].dropna().tolist()\n        smile_texts.extend(texts)\n\n    # 필터링: 위협 키워드 없고 + 길이 20~500자인 것만\n    smile_filtered = [\n        t for t in smile_texts\n        if not contains_threat(t) and 20 < len(str(t)) < 500\n    ]\n\n    # 단문 3개씩 합쳐서 멀티턴 대화 형태로 변환\n    # → DKTC train 데이터가 평균 9~10턴이 하나로 이어진 형태이므로\n    smile_convs = []\n    random.shuffle(smile_filtered)\n    for i in range(0, len(smile_filtered) - 2, 3):  # 3개씩 묶음\n        conv = ' '.join(smile_filtered[i:i+3])\n        if 50 < len(conv) < 500:  # DKTC 데이터 길이 범위에 맞춤\n            smile_convs.append(conv)\n\n    selected = smile_convs[:400]\n    normal_samples.extend(selected)\n    print(f\"  → {len(selected)}개 수집\")\n\nexcept Exception as e:\n    print(f\"  SmileStyle 오류: {e}\")\n    print(\"  → 건너뜀\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# STEP 2-2: 소스 2 - KakaoChatData (목표 300개)\n# [Level 2] 실제 카카오톡 대화 스타일 챗봇 데이터 (~73K쌍)\n# 선택 이유: 실제 메신저 대화 패턴이 DKTC의 대화체와 가장 자연스럽게 일치\n# 처리 방법: Q(질문)+A(답변)를 합치고, 3쌍을 이어 멀티턴 형태로\n# ============================================================\nprint(\"=\"*50)\nprint(\"소스 2: KakaoChatData 카카오톡 대화\")\nprint(\"=\"*50)\n\ntry:\n    kakao_df = pd.read_csv('ChatbotData.csv')\n    print(f\"전체 데이터: {len(kakao_df)}개\")\n    print(f\"컬럼: {list(kakao_df.columns)}\")\n\n    # Q(질문)와 A(답변)를 합쳐서 1턴 대화로 만들기\n    kakao_convs = []\n    for _, row in kakao_df.iterrows():\n        q = str(row.get('Q', row.iloc[0]))\n        a = str(row.get('A', row.iloc[1]))\n        conv = f\"{q} {a}\"  # \"오늘 뭐해? 나 집에 있어\"\n        if not contains_threat(conv) and 20 < len(conv) < 500:\n            kakao_convs.append(conv)\n\n    # 3개 QA쌍을 이어 멀티턴 대화로 변환 (DKTC 형태에 맞춤)\n    random.shuffle(kakao_convs)\n    kakao_multi = []\n    for i in range(0, len(kakao_convs) - 2, 3):\n        conv = ' '.join(kakao_convs[i:i+3])\n        if 80 < len(conv) < 500:\n            kakao_multi.append(conv)\n\n    selected = kakao_multi[:300]\n    normal_samples.extend(selected)\n    print(f\"  → {len(selected)}개 수집\")\n\nexcept Exception as e:\n    print(f\"  KakaoChatData 오류: {e}\")\n    print(\"  → 건너뜀\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# STEP 2-3: 소스 3 - kor_unsmile 비혐오 문장 (목표 200개)\n# [Level 2] 스마일게이트 혐오표현 데이터셋에서 \"비혐오(clean=1)\"만 추출\n# 선택 이유: 혐오 데이터셋의 비혐오 라벨 = \"사람이 검증한 무해한 문장\"\n#           → 일반대화로 사용하기에 신뢰도가 높음\n# 처리 방법: 4개 문장을 합쳐서 대화 형태로 (단문이 많아서)\n# ============================================================\nprint(\"=\"*50)\nprint(\"소스 3: kor_unsmile (비혐오 문장)\")\nprint(\"=\"*50)\n\ntry:\n    # HuggingFace Hub에서 자동 다운로드\n    unsmile_ds = load_dataset('smilegate-ai/kor_unsmile', split='train')\n    unsmile_df = unsmile_ds.to_pandas()\n    print(f\"전체: {len(unsmile_df)}개\")\n    print(f\"컬럼: {list(unsmile_df.columns)}\")\n\n    # clean=1: 사람이 \"비혐오\"로 라벨링한 문장만 추출\n    if 'clean' in unsmile_df.columns:\n        clean_texts = unsmile_df[unsmile_df['clean'] == 1]['문장'].tolist()\n    else:\n        # clean 컬럼이 없으면: 모든 혐오 라벨이 0인 행 = 비혐오\n        label_cols = [c for c in unsmile_df.columns if c not in ['문장', 'clean']]\n        clean_mask = unsmile_df[label_cols].sum(axis=1) == 0\n        clean_texts = unsmile_df[clean_mask]['문장'].tolist()\n\n    # 위협 키워드 필터 + 길이 필터\n    clean_filtered = [\n        t for t in clean_texts\n        if not contains_threat(t) and 10 < len(str(t)) < 300\n    ]\n\n    # 4개 문장씩 합쳐서 대화 형태로 (이 데이터는 단문이 많음)\n    random.shuffle(clean_filtered)\n    unsmile_convs = []\n    for i in range(0, len(clean_filtered) - 3, 4):\n        conv = ' '.join(clean_filtered[i:i+4])\n        if 50 < len(conv) < 500:\n            unsmile_convs.append(conv)\n\n    selected = unsmile_convs[:200]\n    normal_samples.extend(selected)\n    print(f\"  → {len(selected)}개 수집\")\n\nexcept Exception as e:\n    print(f\"  kor_unsmile 오류: {e}\")\n    print(\"  → 건너뜀\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# STEP 2-4: 소스 4 - NSMC 네이버 영화리뷰 (목표 100개)\n# [Level 2] Ex06에서 다뤘던 NSMC 데이터를 다른 용도로 재활용\n# 선택 이유: 긍정 리뷰 중 일상 감정표현(\"재밌\", \"대박\") = 무해한 일상어\n# 처리 방법: 5개 리뷰를 합쳐서 잡담 대화처럼 구성\n# 주의: 리뷰 데이터이므로 대화체가 아님 → 보조 소스로만 사용 (100개)\n# ============================================================\nprint(\"=\"*50)\nprint(\"소스 4: NSMC 네이버 영화리뷰 (긍정+일상)\")\nprint(\"=\"*50)\n\ntry:\n    nsmc_ds = load_dataset('nsmc', split='train')\n    nsmc_df = nsmc_ds.to_pandas()\n    print(f\"전체: {len(nsmc_df)}개\")\n\n    # 일상적 긍정 키워드가 포함된 리뷰만 선별\n    # → \"존나 재밌다\" 같은 구어체 표현이 DKTC 스타일과 어느 정도 유사\n    daily_keywords = ['재밌', '좋았', '최고', '감동', '웃기', '대박', '꿀잼',\n                      '힐링', '따뜻', '행복', '사랑']\n\n    positive = nsmc_df[nsmc_df['label'] == 1]['document'].dropna().tolist()\n    daily_reviews = [\n        t for t in positive\n        if any(kw in str(t) for kw in daily_keywords)  # 일상 키워드 포함\n        and not contains_threat(t)                       # 위협 키워드 미포함\n        and 15 < len(str(t)) < 200                      # 적절한 길이\n    ]\n\n    # 5개 리뷰를 합쳐서 잡담 대화처럼 길이 맞추기\n    random.shuffle(daily_reviews)\n    nsmc_convs = []\n    for i in range(0, len(daily_reviews) - 4, 5):\n        conv = ' '.join(daily_reviews[i:i+5])\n        if 80 < len(conv) < 500:\n            nsmc_convs.append(conv)\n\n    selected = nsmc_convs[:100]\n    normal_samples.extend(selected)\n    print(f\"  → {len(selected)}개 수집\")\n\nexcept Exception as e:\n    print(f\"  NSMC 오류: {e}\")\n    print(\"  → 건너뜀\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# STEP 2-5: 소스 5 - 경계 케이스 (25개) ⭐ 핵심 차별화 포인트\n# [Level 2] 직접 설계한 \"위협처럼 보이지만 실제로는 일반인\" 대화\n#\n# 왜 필요한가?\n#   한국어 구어체에서 \"야 죽을래 ㅋㅋ\", \"돈 내놔 ㅋㅋ\" 같은 표현은\n#   표면적으로 위협 키워드를 포함하지만 실제로는 친구 간 농담임.\n#   이런 경계 케이스가 없으면 모델이 키워드만 보고 과잉 분류(false positive)함.\n#\n# 설계 원칙: 4가지 혼동 패턴을 커버\n#   1. 협박 키워드 + 실제 농담 (\"죽을래 ㅋㅋ\")\n#   2. 갈취 키워드 + 실제 친구 부탁 (\"천원만 빌려줘\")\n#   3. 직장 키워드 + 실제 일상 스트레스 (\"퇴사하고 싶다 ㅋㅋ\")\n#   4. 순수 일상 대화 (\"치킨 먹을까 피자 먹을까\")\n# ============================================================\nprint(\"=\"*50)\nprint(\"소스 5: 경계 케이스 (위협처럼 보이지만 일반)\")\nprint(\"=\"*50)\n\nboundary_cases = [\n    # ── 패턴 1: 협박처럼 보이는 농담 ──\n    \"야 죽을래 ㅋㅋ 아 진짜 웃겨서 죽겠다 아 배아파 ㅋㅋㅋ 진짜 미쳤어 너 개그맨 해라\",\n    \"야 너 진짜 맞을래 ㅋㅋ 아 왜 그런 말을 해서 웃기게 만들어 아 진짜 복근 생기겠다\",\n    \"때려치우고 싶다 뭘 회사 오늘 진짜 힘들었어 야 치킨 먹자 나 오늘 자격 있어\",\n    \"돈 내놔 ㅋㅋ 밥값 네가 쏜다며 아 맞다 내가 쏜다고 했지 ㅋㅋ 어디 갈까\",\n    \"너 진짜 미쳤다 ㅋㅋ 이걸 어떻게 생각해내 와 천재 아니야 대단하다 진짜\",\n\n    # ── 패턴 2: 갈취처럼 보이는 친구 대화 ──\n    \"야 담배 한 개비 줘봐 아 나 오늘 스트레스 받아서 한 대만 ㅋㅋ 고마워 내일 사줄게\",\n    \"야 천원만 빌려줘 자판기 커피 마시고 싶은데 지갑을 놓고 왔어 내일 바로 갚을게\",\n    \"이거 나 좀 줘 뭐 이 과자 맛있어 보여서 하나만 줘봐 오 진짜 맛있다\",\n    \"야 그거 빌려줘 뭘 충전기 배터리 없어서 잠깐만 쓸게 고마워\",\n    \"밥 사라 ㅋㅋ 야 오늘 내 생일인데 당연히 네가 사야지 어디 갈까\",\n\n    # ── 패턴 3: 직장 괴롭힘처럼 보이는 일상 스트레스 ──\n    \"오늘 야근이야 또 아 진짜 힘들다 그래도 이번 프로젝트 끝나면 좀 쉴 수 있겠지\",\n    \"회의 또 해 진짜 오늘만 세번째야 그래도 뭐 좋은 아이디어 나왔으니까 괜찮아\",\n    \"상사가 또 일 줬어 근데 뭐 그래도 인정해주니까 열심히 해야지 파이팅\",\n    \"퇴사하고 싶다 ㅋㅋ 아 농담이야 월급날이니까 참는거지 오늘 뭐 먹을까\",\n    \"야 우리 부장님 또 회식 잡았대 아 귀찮다 그래도 고기니까 ㅋㅋ 가자\",\n\n    # ── 패턴 4: 순수 일상 대화 (위협 요소 없음) ──\n    \"이거 들어봐 와 이 노래 진짜 좋다 그치 요즘 이것만 들어 중독됐어\",\n    \"야 오늘 날씨 진짜 좋다 나가자 어디 갈까 한강 갈까 치킨 시켜서 먹자\",\n    \"게임 할래 뭐 할까 롤 할까 발로란트 할까 아 나 롤 밴당했어 ㅋㅋ 발로 하자\",\n    \"드라마 봤어 뭐 그 어제 나온거 아 진짜 재밌었어 다음주가 기대된다\",\n    \"배고프다 뭐 먹을까 치킨 먹을까 피자 먹을까 둘 다 시킬까 ㅋㅋ 그러자\",\n    \"야 주말에 뭐해 나 아무것도 안해 그러면 놀자 어디 갈까 영화 보러 갈까\",\n    \"시험 망했어 ㅋㅋ 아 그래도 뭐 다음에 잘하면 되지 오늘은 놀자\",\n    \"운동 갈래 같이 헬스장 갈까 아 귀찮은데 그래도 가야지 건강이 최고야\",\n    \"엄마가 용돈 줬어 ㅋㅋ 얼마 5만원 와 부럽다 나도 달라고 해야지\",\n    \"택배 왔다 뭐 시켰어 아 그거 옷 샀어 예쁘지 응 잘 어울린다\"\n]\n\nnormal_samples.extend(boundary_cases)\nprint(f\"  → {len(boundary_cases)}개 추가\")\n\nprint(f\"\\n{'='*50}\")\nprint(f\"총 합성 일반대화: {len(normal_samples)}개\")\nprint(f\"{'='*50}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# STEP 2-6: 합성 데이터를 train에 통합\n# [Level 2] 5개 소스에서 수집한 일반대화를 하나의 DataFrame으로 합침\n# → 원본 train(3,950개, 4클래스) + 합성 일반대화(~1000개) = train_full\n# ============================================================\n\n# 합성 데이터를 DataFrame으로 변환\nnormal_df = pd.DataFrame({\n    'idx': [f'n_{i:03d}' for i in range(len(normal_samples))],  # n_000, n_001, ...\n    'class': '일반 대화',                                         # 라벨은 \"일반 대화\"\n    'conversation': normal_samples\n})\n\nprint(f\"합성 일반대화 DataFrame: {len(normal_df)}개\")\nprint(f\"샘플:\")\nfor i in range(min(3, len(normal_df))):\n    print(f\"  [{i}] {normal_df.iloc[i]['conversation'][:80]}...\")\n\n# 원본 train과 합성 데이터를 concat\n# → 이제 5개 클래스가 모두 존재하는 완전한 학습 데이터셋!\ntrain_full = pd.concat([train_df[['idx', 'class', 'conversation']], normal_df],\n                       ignore_index=True)\nprint(f\"\\n통합 train: {len(train_full)}개\")\nprint(f\"\\n클래스 분포 (이제 5개 클래스 모두 있음!):\")\nprint(train_full['class'].value_counts())"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## STEP 3: 전처리 & 토크나이저\n> **Level 1 (베이스라인)** — Ex06(NSMC 감성분석) + Ex07(SentencePiece 토큰화)에서 배운 패턴\n>\n> - Ex06: 텍스트 정제 함수 패턴 (정규식, 특수문자 제거)\n> - Ex07: 한국어 토큰화 원리 이해 → ELECTRA의 WordPiece가 구어체를 어떻게 처리하는지 파악\n> - **핵심**: 구어체/반말 특성(ㅋㅋ, ㅠㅠ 등)을 보존하면서 노이즈만 제거"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# STEP 3-1: 텍스트 전처리 함수\n# [Level 1] Ex06에서 배운 텍스트 정제 패턴 적용\n#\n# 설계 원칙: \"최소한의 전처리\"\n#   DKTC 데이터는 반말+구어체 → \"ㅋㅋ\", \"ㅠㅠ\", \"~\" 등이 의미를 가짐\n#   예: \"죽을래 ㅋㅋ\" (농담) vs \"죽을래\" (위협) → ㅋㅋ를 제거하면 구분 불가!\n#   따라서 구어체 요소는 보존하고, 의미없는 특수문자만 제거\n# ============================================================\nimport re\n\ndef preprocess(text):\n    \"\"\"텍스트 전처리 - 구어체 보존, 노이즈만 제거\"\"\"\n    text = str(text)\n    text = re.sub(r'\\s+', ' ', text)  # 연속 공백 → 공백 1개로 통일\n    # 한글(가-힣) + 영숫자 + 자음/모음(ㅋㅎㅠㅜ) + 기본 문장부호만 보존\n    # → ㅋ, ㅎ, ㅠ, ㅜ는 감정 표현이므로 반드시 보존!\n    text = re.sub(r'[^가-힣a-zA-Z0-9ㄱ-ㅎㅏ-ㅣ\\s,.!?~ㅋㅎㅠㅜ]', '', text)\n    return text.strip()\n\n# train과 test 모두에 동일한 전처리 적용 (일관성 중요!)\ntrain_full['conversation'] = train_full['conversation'].apply(preprocess)\ntest_df['conversation'] = test_df['conversation'].apply(preprocess)\n\n# 문자열 클래스명 → 정수 라벨로 변환 (모델 학습에 필요)\n# \"협박 대화\" → 0, \"갈취 대화\" → 1, ... \"일반 대화\" → 4\ntrain_full['label'] = train_full['class'].map(CLASS2IDX)\n\n# NaN 체크: 매핑 안 된 클래스가 있으면 코드 오류\nprint(f\"라벨 NaN 수: {train_full['label'].isna().sum()}\")\nif train_full['label'].isna().sum() > 0:\n    print(\"⚠️ 매핑 안 된 클래스:\")\n    print(train_full[train_full['label'].isna()]['class'].unique())\n\ntrain_full['label'] = train_full['label'].astype(int)\nprint(f\"\\n라벨 분포:\")\nprint(train_full['label'].value_counts().sort_index())\nprint(f\"\\n전처리 샘플:\")\nprint(train_full.iloc[0]['conversation'][:100])"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# STEP 3-2: KcELECTRA 토크나이저 로드 + 토큰 길이 분석\n# [Level 1] Ex07(SentencePiece)에서 배운 토큰화 개념 활용\n# [Level 2] Ex09(Transformer)에서 배운 Pre-trained 모델 활용\n#\n# KcELECTRA 토크나이저 = WordPiece 방식\n#   Ex07에서 배운 SentencePiece와 유사한 서브워드 토큰화\n#   \"죽겠다\" → [\"죽\", \"##겠\", \"##다\"] 처럼 분리\n#   한국어 댓글/구어체로 학습된 vocab이므로 \"ㅋㅋ\", \"ㅠㅠ\" 등도 잘 처리\n#\n# MAX_LEN 검증: 95%ile 이하면 대부분의 데이터가 잘리지 않음\n# ============================================================\ntokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\nprint(f\"토크나이저: {MODEL_NAME}\")\nprint(f\"Vocab size: {tokenizer.vocab_size}\")\n\n# 전체 데이터의 토큰 길이 분포 확인\n# → MAX_LEN=256이 적절한지 데이터로 검증\ntoken_lens = []\nfor text in train_full['conversation'].values:\n    tokens = tokenizer.encode(text, add_special_tokens=True)  # [CLS] + tokens + [SEP]\n    token_lens.append(len(tokens))\n\nprint(f\"\\n토큰 길이 통계:\")\nprint(f\"  평균: {np.mean(token_lens):.1f}\")\nprint(f\"  최대: {np.max(token_lens)}\")\nprint(f\"  95%ile: {np.percentile(token_lens, 95):.0f}\")\n# 95% 이상 커버되면 MAX_LEN이 적절한 것\nprint(f\"  MAX_LEN={MAX_LEN}으로 커버되는 비율: {sum(1 for l in token_lens if l <= MAX_LEN)/len(token_lens)*100:.1f}%\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## STEP 4: Dataset, Focal Loss, R-Drop 정의\n> **Level 2 (최신 논문 기법 적용)** — 3개의 핵심 컴포넌트 정의\n>\n> | 컴포넌트 | 논문 | 왜 적용했나 |\n> |----------|------|-------------|\n> | DKTCDataset | Ex06 NSMCDataset 패턴 | PyTorch Dataset 구조 (\\_\\_getitem\\_\\_ 패턴) |\n> | **Focal Loss** | Lin et al., 2017 \"Focal Loss for Dense Object Detection\" | 합성 후에도 일반대화 비율이 다름 → 소수 클래스에 더 큰 가중치 |\n> | **R-Drop** | Liang et al., 2021 \"R-Drop: Regularized Dropout for Neural Networks\" | ~5K 소규모 데이터 → 과적합 위험 → 드롭아웃 정규화로 방지 |"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# STEP 4: Dataset, FocalLoss, R-Drop 정의\n# ============================================================\n\n# ──────────────────────────────────────────────\n# (1) DKTCDataset: PyTorch Dataset 클래스\n# [Level 1] Ex06의 NSMCDataset 패턴을 그대로 활용\n#   Ex06에서 배운 것: __getitem__에서 토크나이저 호출 → 텐서 반환\n#   달라진 점: NSMC는 2클래스(긍정/부정), DKTC는 5클래스\n# ──────────────────────────────────────────────\nclass DKTCDataset(Dataset):\n    \"\"\"\n    DKTC 데이터셋 (Ex06 NSMCDataset 패턴)\n    텍스트 → 토크나이저 → input_ids + attention_mask + labels\n    \"\"\"\n    def __init__(self, texts, labels=None, tokenizer=None, max_len=256):\n        self.texts = texts\n        self.labels = labels       # None이면 test 데이터 (라벨 없음)\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, idx):\n        text = str(self.texts[idx])\n        # 토크나이저가 텍스트를 토큰 ID로 변환\n        # padding='max_length': 모든 샘플을 같은 길이로 맞춤 (배치 처리용)\n        # truncation=True: MAX_LEN 초과 시 자름\n        encoding = self.tokenizer(\n            text,\n            max_length=self.max_len,\n            padding='max_length',\n            truncation=True,\n            return_tensors='pt'\n        )\n        item = {\n            'input_ids': encoding['input_ids'].squeeze(0),       # [MAX_LEN] 토큰 ID\n            'attention_mask': encoding['attention_mask'].squeeze(0),  # [MAX_LEN] 패딩=0, 실제=1\n        }\n        # ELECTRA는 token_type_ids도 사용 (BERT와 동일)\n        if 'token_type_ids' in encoding:\n            item['token_type_ids'] = encoding['token_type_ids'].squeeze(0)\n        if self.labels is not None:\n            item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n        return item\n\n\n# ──────────────────────────────────────────────\n# (2) Focal Loss: 클래스 불균형 해결\n# [Level 2] 논문: Lin et al., 2017 \"Focal Loss for Dense Object Detection\"\n#\n# 왜 적용했나?\n#   합성 후에도 클래스 비율이 다름 (협박 896 vs 일반 ~1000)\n#   CE Loss는 모든 샘플에 동일한 가중치 → 다수 클래스에 편향\n#   Focal Loss는 \"이미 잘 맞추는 쉬운 샘플\"의 가중치를 줄이고\n#   \"틀리기 쉬운 어려운 샘플\"에 집중 → 소수 클래스 성능 향상\n#\n# 수식: FL(pt) = -alpha * (1-pt)^gamma * log(pt)\n#   pt = 모델이 정답에 부여한 확률\n#   gamma = 2.0 (기본값): pt가 높으면 (1-pt)^2 ≈ 0 → 쉬운 샘플 무시\n#   alpha = 클래스별 가중치 (역빈도 기반)\n# ──────────────────────────────────────────────\nclass FocalLoss(nn.Module):\n    \"\"\"Focal Loss (Lin et al., 2017)\"\"\"\n    def __init__(self, alpha=None, gamma=2.0, reduction='mean'):\n        super().__init__()\n        self.alpha = alpha   # 클래스별 가중치 텐서 (역빈도 기반으로 계산)\n        self.gamma = gamma   # focusing parameter: 클수록 어려운 샘플에 더 집중\n        self.reduction = reduction\n\n    def forward(self, inputs, targets):\n        # 1단계: 일반 CE Loss 계산 (클래스 가중치 적용)\n        ce_loss = F.cross_entropy(inputs, targets, weight=self.alpha, reduction='none')\n        # 2단계: pt = 정답 클래스의 예측 확률\n        pt = torch.exp(-ce_loss)  # exp(-CE) = 정답 확률\n        # 3단계: Focal 가중치 적용 → 쉬운 샘플(pt 높음)은 가중치 ↓\n        focal_loss = ((1 - pt) ** self.gamma) * ce_loss\n\n        if self.reduction == 'mean':\n            return focal_loss.mean()\n        elif self.reduction == 'sum':\n            return focal_loss.sum()\n        return focal_loss\n\n\n# ──────────────────────────────────────────────\n# (3) R-Drop: 드롭아웃 정규화\n# [Level 2] 논문: Liang et al., 2021 \"R-Drop: Regularized Dropout\"\n#\n# 왜 적용했나?\n#   데이터가 ~5K로 소규모 → Pre-trained 모델도 과적합 위험\n#   R-Drop 원리: 같은 입력을 2번 forward pass (드롭아웃이 다르게 적용됨)\n#   → 두 출력이 비슷해지도록 KL Divergence를 추가 loss로 사용\n#   → 드롭아웃에 의한 \"노이즈\"에 덜 민감해짐 = 일반화 능력 향상\n#\n# 수식: L = CE_loss + alpha * KL_div(output1 || output2)\n#   alpha = 0.7 (KL loss의 가중치, 논문 권장값)\n# ──────────────────────────────────────────────\ndef compute_rdrop_loss(logits1, logits2, labels, loss_fn, alpha=0.7):\n    \"\"\"\n    R-Drop Loss (Liang et al., 2021)\n    같은 입력 2번 forward → CE 평균 + alpha * 양방향 KL Divergence\n    \"\"\"\n    # CE/Focal loss 2개의 평균\n    loss1 = loss_fn(logits1, labels)\n    loss2 = loss_fn(logits2, labels)\n    ce_loss = (loss1 + loss2) / 2\n\n    # 양방향 KL Divergence: P→Q와 Q→P 모두 계산하여 대칭성 확보\n    p = F.log_softmax(logits1, dim=-1)  # 첫 번째 forward 결과의 log 확률\n    q = F.log_softmax(logits2, dim=-1)  # 두 번째 forward 결과의 log 확률\n    kl_loss = (\n        F.kl_div(p, q.exp(), reduction='batchmean') +  # KL(Q || P)\n        F.kl_div(q, p.exp(), reduction='batchmean')     # KL(P || Q)\n    ) / 2\n\n    # 최종 loss = 분류 loss + alpha * 정규화 loss\n    return ce_loss + alpha * kl_loss\n\n\nprint(\"Dataset, FocalLoss, R-Drop 정의 완료\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## STEP 5: Ablation 실험 실행\n> **Level 3 (Ablation Study로 정량 검증)** — Ex03(CIFAR-10 Ablation Study)에서 배운 실험 설계\n>\n> **Ablation Study란?** (Ex03에서 배운 핵심 개념)\n> - 모델에 적용한 기법을 하나씩 빼거나 추가하면서 **각 기법의 기여도**를 측정\n> - \"이 기법이 정말 도움이 되는가?\"를 **숫자로 증명**\n>\n> | 실험 | Loss | R-Drop | 합성데이터 | 비교 포인트 |\n> |------|------|--------|-----------|------------|\n> | Exp1 | CE Loss | X | 전체 | **baseline** (비교 기준점) |\n> | Exp2 | **Focal** Loss | X | 전체 | Exp1 대비 F1 ↑ → **불균형 해결 효과** 증명 |\n> | Exp3 | Focal Loss | **O** (α=0.7) | 전체 | Exp2 대비 F1 ↑ → **과적합 방지 효과** 증명 |\n> | Exp4 | Focal Loss | O | **500개 축소** | Exp3 대비 F1 ↓ → **데이터 양의 중요성** 증명 |"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# STEP 5-1: 학습/검증 함수 정의\n# [Level 1] Ex06에서 배운 학습 루프 패턴을 확장\n#   Ex06: 단순 for epoch → for batch → loss.backward()\n#   확장: R-Drop 분기, gradient clipping, scheduler 추가\n# ============================================================\n\ndef train_one_epoch(model, dataloader, optimizer, scheduler, loss_fn,\n                    use_rdrop=False, rdrop_alpha=0.7):\n    \"\"\"\n    1 epoch 학습\n    use_rdrop=True일 때: 같은 배치를 2번 forward → R-Drop loss 적용\n    \"\"\"\n    model.train()  # 학습 모드 (드롭아웃 활성화 → R-Drop의 핵심!)\n    total_loss = 0\n    all_preds, all_labels = [], []\n\n    for batch in dataloader:\n        # GPU로 데이터 이동\n        input_ids = batch['input_ids'].to(DEVICE)\n        attention_mask = batch['attention_mask'].to(DEVICE)\n        labels = batch['labels'].to(DEVICE)\n\n        model_kwargs = {'input_ids': input_ids, 'attention_mask': attention_mask}\n        if 'token_type_ids' in batch:\n            model_kwargs['token_type_ids'] = batch['token_type_ids'].to(DEVICE)\n\n        if use_rdrop:\n            # [Level 2] R-Drop: 같은 입력으로 2번 forward\n            # → 드롭아웃이 랜덤이므로 출력이 약간 다름\n            # → 이 차이를 줄이도록 학습 = 더 안정적인 모델\n            outputs1 = model(**model_kwargs)  # 1번째 forward (드롭아웃 A)\n            outputs2 = model(**model_kwargs)  # 2번째 forward (드롭아웃 B)\n            loss = compute_rdrop_loss(\n                outputs1.logits, outputs2.logits, labels,\n                loss_fn, alpha=rdrop_alpha\n            )\n            logits = outputs1.logits\n        else:\n            # 일반 학습: 1번 forward\n            outputs = model(**model_kwargs)\n            logits = outputs.logits\n            loss = loss_fn(logits, labels)\n\n        # 역전파 + 최적화\n        optimizer.zero_grad()                                       # 기울기 초기화\n        loss.backward()                                             # 역전파\n        torch.nn.utils.clip_grad_norm_(model.parameters(), MAX_GRAD_NORM)  # 기울기 폭발 방지\n        optimizer.step()                                            # 가중치 업데이트\n        scheduler.step()                                            # 학습률 조정\n\n        total_loss += loss.item()\n        preds = torch.argmax(logits, dim=-1)  # 가장 높은 확률의 클래스 = 예측\n        all_preds.extend(preds.cpu().numpy())\n        all_labels.extend(labels.cpu().numpy())\n\n    avg_loss = total_loss / len(dataloader)\n    acc = accuracy_score(all_labels, all_preds)\n    f1 = f1_score(all_labels, all_preds, average='macro')  # macro: 클래스별 F1의 평균\n    return avg_loss, acc, f1\n\n\ndef evaluate(model, dataloader, loss_fn):\n    \"\"\"검증 (드롭아웃 비활성화 → 결정론적 출력)\"\"\"\n    model.eval()  # 평가 모드 (드롭아웃 OFF)\n    total_loss = 0\n    all_preds, all_labels = [], []\n\n    with torch.no_grad():  # 기울기 계산 불필요 → 메모리 절약\n        for batch in dataloader:\n            input_ids = batch['input_ids'].to(DEVICE)\n            attention_mask = batch['attention_mask'].to(DEVICE)\n            labels = batch['labels'].to(DEVICE)\n\n            model_kwargs = {'input_ids': input_ids, 'attention_mask': attention_mask}\n            if 'token_type_ids' in batch:\n                model_kwargs['token_type_ids'] = batch['token_type_ids'].to(DEVICE)\n\n            outputs = model(**model_kwargs)\n            logits = outputs.logits\n            loss = loss_fn(logits, labels)\n\n            total_loss += loss.item()\n            preds = torch.argmax(logits, dim=-1)\n            all_preds.extend(preds.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n\n    avg_loss = total_loss / len(dataloader)\n    acc = accuracy_score(all_labels, all_preds)\n    f1 = f1_score(all_labels, all_preds, average='macro')\n    return avg_loss, acc, f1, all_preds, all_labels\n\n\nprint(\"학습/검증 함수 정의 완료\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# STEP 5-2: 실험 실행 함수 (Ablation 공통 프레임워크)\n# [Level 3] Ex03에서 배운 Ablation Study 패턴\n#   핵심: 모든 실험이 동일한 함수를 사용 → 공정한 비교 보장\n#   다른 것: loss_fn, use_rdrop, 데이터만 변경\n# ============================================================\n\ndef run_experiment(exp_name, train_data, val_data, loss_fn,\n                   use_rdrop=False, rdrop_alpha=0.7, epochs=EPOCHS):\n    \"\"\"\n    Ablation 실험 실행 함수\n    → 동일 구조에서 loss/R-Drop/데이터만 바꿔가며 공정 비교\n    Returns: history + best model state + validation 예측 결과\n    \"\"\"\n    print(f\"\\n{'='*60}\")\n    print(f\"  {exp_name}\")\n    print(f\"  Loss: {type(loss_fn).__name__}, R-Drop: {use_rdrop}, Data: {len(train_data)}\")\n    print(f\"{'='*60}\")\n\n    # ── 데이터 준비 ──\n    train_dataset = DKTCDataset(\n        train_data['conversation'].values,\n        train_data['label'].values,\n        tokenizer, MAX_LEN\n    )\n    val_dataset = DKTCDataset(\n        val_data['conversation'].values,\n        val_data['label'].values,\n        tokenizer, MAX_LEN\n    )\n    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n\n    # ── 모델: 매 실험마다 새로 초기화 (공정 비교!) ──\n    # [Level 2] Ex09에서 배운 Pre-trained 모델 Fine-tuning\n    # AutoModelForSequenceClassification: ELECTRA + 분류 head(5클래스)\n    model = AutoModelForSequenceClassification.from_pretrained(\n        MODEL_NAME, num_labels=NUM_CLASSES\n    ).to(DEVICE)\n\n    # ── 옵티마이저: AdamW (BERT 계열 표준) ──\n    optimizer = torch.optim.AdamW(\n        model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY\n    )\n    # ── 스케줄러: linear warmup → 선형 감소 ──\n    # 처음 10% 스텝은 LR을 0→2e-5로 서서히 올림 (안정적 시작)\n    # 이후 선형으로 감소 → 수렴 안정성\n    total_steps = len(train_loader) * epochs\n    warmup_steps = int(total_steps * WARMUP_RATIO)\n    scheduler = get_linear_schedule_with_warmup(\n        optimizer, warmup_steps, total_steps\n    )\n\n    # ── 학습 루프 ──\n    history = {\n        'train_loss': [], 'train_acc': [], 'train_f1': [],\n        'val_loss': [], 'val_acc': [], 'val_f1': []\n    }\n    best_val_f1 = 0\n    best_state = None\n\n    for epoch in range(epochs):\n        train_loss, train_acc, train_f1 = train_one_epoch(\n            model, train_loader, optimizer, scheduler, loss_fn,\n            use_rdrop=use_rdrop, rdrop_alpha=rdrop_alpha\n        )\n        val_loss, val_acc, val_f1, _, _ = evaluate(model, val_loader, loss_fn)\n\n        # 이력 저장 (STEP 6 시각화용)\n        history['train_loss'].append(train_loss)\n        history['train_acc'].append(train_acc)\n        history['train_f1'].append(train_f1)\n        history['val_loss'].append(val_loss)\n        history['val_acc'].append(val_acc)\n        history['val_f1'].append(val_f1)\n\n        # Best 모델 저장: Val F1이 가장 높은 epoch의 가중치 보관\n        if val_f1 > best_val_f1:\n            best_val_f1 = val_f1\n            best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n\n        print(f\"  Epoch {epoch+1}/{epochs} | \"\n              f\"Train Loss: {train_loss:.4f} Acc: {train_acc:.4f} F1: {train_f1:.4f} | \"\n              f\"Val Loss: {val_loss:.4f} Acc: {val_acc:.4f} F1: {val_f1:.4f}\"\n              f\"{' ★' if val_f1 >= best_val_f1 else ''}\")\n\n    print(f\"  → Best Val F1: {best_val_f1:.4f}\")\n\n    # Best 모델로 최종 검증 (Confusion Matrix용 예측값 수집)\n    model.load_state_dict(best_state)\n    model.to(DEVICE)\n    _, _, _, val_preds, val_labels = evaluate(model, val_loader, loss_fn)\n\n    # GPU 메모리 정리 (다음 실험을 위해)\n    del model\n    torch.cuda.empty_cache()\n\n    return {\n        'name': exp_name,\n        'history': history,\n        'best_val_f1': best_val_f1,\n        'best_state': best_state,\n        'val_preds': val_preds,\n        'val_labels': val_labels\n    }\n\nprint(\"실험 함수 정의 완료\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# STEP 5-3: 데이터 분할 (Stratified Split)\n# [Level 1] 검증셋 구성 - 클래스 비율을 유지하는 분할\n#   stratify: 원본 비율 그대로 train/val에 분배\n#   → 검증셋에도 5개 클래스가 고르게 포함되어야 공정한 평가\n# ============================================================\n\n# 전체 데이터 분할 (Exp1~3용)\ntrain_split, val_split = train_test_split(\n    train_full, test_size=VAL_RATIO,       # 15% 검증셋\n    stratify=train_full['label'],           # 클래스 비율 유지!\n    random_state=SEED                       # 재현성\n)\nprint(f\"Train split: {len(train_split)}, Val split: {len(val_split)}\")\nprint(f\"\\nTrain 라벨 분포:\")\nprint(train_split['label'].value_counts().sort_index())\nprint(f\"\\nVal 라벨 분포:\")\nprint(val_split['label'].value_counts().sort_index())\n\n# ── Exp4용 축소 데이터 ──\n# [Level 3] Ablation: 합성 일반대화를 500개로 줄여서 \"데이터 양의 영향\" 측정\n# → Exp3(전체) vs Exp4(축소) 비교 → 데이터가 많을수록 좋다는 것을 증명\nnormal_500 = train_full[train_full['label'] == 4].sample(\n    n=min(500, len(train_full[train_full['label']==4])),\n    random_state=SEED\n)\noriginal_data = train_full[train_full['label'] != 4]  # 원본 4클래스는 그대로\ntrain_reduced = pd.concat([original_data, normal_500], ignore_index=True)\ntrain_reduced_split, val_reduced_split = train_test_split(\n    train_reduced, test_size=VAL_RATIO, stratify=train_reduced['label'],\n    random_state=SEED\n)\nprint(f\"\\nExp4 축소 데이터: {len(train_reduced)}개\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# STEP 5-4: 클래스 가중치 계산 (Focal Loss의 alpha 파라미터)\n# [Level 2] 역빈도(inverse frequency) 방식\n#   클래스별 가중치 = 전체 샘플 수 / (클래스 수 × 해당 클래스 샘플 수)\n#   → 적은 클래스일수록 가중치 ↑ → Focal Loss가 소수 클래스에 더 집중\n# ============================================================\nlabel_counts = train_split['label'].value_counts().sort_index()\ntotal = len(train_split)\nclass_weights = torch.tensor(\n    [total / (NUM_CLASSES * count) for count in label_counts.values],\n    dtype=torch.float32\n).to(DEVICE)\nprint(f\"클래스 가중치: {class_weights}\")\n# 예: 일반대화가 적으면 가중치 > 1.0, 많으면 < 1.0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# [Level 3] Ablation Exp1: CE Loss (Baseline)\n# ============================================================\n# 비교 기준점(baseline): 가장 기본적인 설정\n# → CE Loss + R-Drop 없음\n# → 이 결과와 비교해서 Focal Loss, R-Drop의 효과를 측정\n# ============================================================\nce_loss_fn = nn.CrossEntropyLoss().to(DEVICE)\nresult1 = run_experiment(\n    'Exp1: CE Loss (Baseline)',\n    train_split, val_split, ce_loss_fn,\n    use_rdrop=False  # R-Drop 없음\n)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# [Level 3] Ablation Exp2: Focal Loss (불균형 해결 효과 측정)\n# ============================================================\n# 변경: CE Loss → Focal Loss (Lin et al., 2017)\n# 비교: Exp1(CE) vs Exp2(Focal) → F1 차이 = Focal Loss의 기여도\n# 기대: 소수 클래스(일반대화) F1 ↑, 전체 macro F1 ↑\n# ============================================================\nfocal_loss_fn = FocalLoss(alpha=class_weights, gamma=2.0).to(DEVICE)\nresult2 = run_experiment(\n    'Exp2: Focal Loss',\n    train_split, val_split, focal_loss_fn,\n    use_rdrop=False  # 아직 R-Drop 없음 (하나만 변경해서 비교)\n)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# [Level 3] Ablation Exp3: Focal Loss + R-Drop (과적합 방지 효과 측정)\n# ============================================================\n# 변경: R-Drop 추가 (Liang et al., 2021)\n# 비교: Exp2(Focal만) vs Exp3(Focal+R-Drop) → F1 차이 = R-Drop의 기여도\n# 기대: train-val F1 gap 감소 (과적합 완화), val F1 ↑\n# ============================================================\nfocal_loss_fn3 = FocalLoss(alpha=class_weights, gamma=2.0).to(DEVICE)\nresult3 = run_experiment(\n    'Exp3: Focal + R-Drop (Full Data)',\n    train_split, val_split, focal_loss_fn3,\n    use_rdrop=True, rdrop_alpha=0.7  # R-Drop ON, alpha=0.7 (논문 권장)\n)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# [Level 3] Ablation Exp4: 축소 데이터 (합성 데이터 양의 영향 측정)\n# ============================================================\n# 변경: 합성 일반대화를 ~1000개 → 500개로 축소\n# 비교: Exp3(전체) vs Exp4(축소) → F1 차이 = 합성 데이터 양의 중요성\n# 기대: 데이터가 줄면 F1 ↓ → \"5개 소스 통합\"의 가치 증명\n# ============================================================\n\n# 축소 데이터용 클래스 가중치 재계산 (비율이 달라졌으므로)\nlabel_counts_r = train_reduced_split['label'].value_counts().sort_index()\ntotal_r = len(train_reduced_split)\nclass_weights_r = torch.tensor(\n    [total_r / (NUM_CLASSES * count) for count in label_counts_r.values],\n    dtype=torch.float32\n).to(DEVICE)\n\nfocal_loss_fn4 = FocalLoss(alpha=class_weights_r, gamma=2.0).to(DEVICE)\nresult4 = run_experiment(\n    'Exp4: Focal + R-Drop (Reduced Data)',\n    train_reduced_split, val_reduced_split, focal_loss_fn4,\n    use_rdrop=True, rdrop_alpha=0.7\n)\n\n# 모든 실험 결과를 리스트로 모음 (STEP 6 시각화용)\nresults = [result1, result2, result3, result4]\nprint(\"\\n\" + \"=\"*60)\nprint(\"  모든 Ablation 실험 완료!\")\nprint(\"=\"*60)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## STEP 6: 결과 시각화\n> **Level 3 (Ablation 결과 정량 검증)** — Ex03 시각화 패턴 적용\n>\n> 3가지 시각화로 각 기법의 기여도를 **눈으로 확인**:\n> 1. **결과 요약 테이블**: F1/Acc 숫자 비교\n> 2. **학습 곡선 (4개 그래프)**: 과적합 여부, 수렴 패턴 확인\n> 3. **Confusion Matrix (4개)**: 어떤 클래스를 혼동하는지 확인"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# STEP 6-1: Ablation 결과 요약 테이블\n# [Level 3] 각 기법의 기여도를 숫자로 비교\n#   읽는 법: Exp1→Exp2 F1 차이 = Focal Loss 효과\n#           Exp2→Exp3 F1 차이 = R-Drop 효과\n#           Exp3→Exp4 F1 차이 = 데이터 양 효과\n# ============================================================\nprint(\"\\n\" + \"=\"*70)\nprint(\"  Ablation Study 결과 요약\")\nprint(\"=\"*70)\nprint(f\"{'실험':<35} {'Best Val F1':>12} {'Best Val Acc':>12}\")\nprint(\"-\"*70)\nfor r in results:\n    best_acc = max(r['history']['val_acc'])\n    print(f\"{r['name']:<35} {r['best_val_f1']:>12.4f} {best_acc:>12.4f}\")\nprint(\"-\"*70)\n\n# 가장 좋은 실험 자동 선택 (F1 기준)\nbest_exp = max(results, key=lambda x: x['best_val_f1'])\nprint(f\"\\n★ Best: {best_exp['name']} (F1={best_exp['best_val_f1']:.4f})\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# STEP 6-2: 학습 곡선 시각화\n# [Level 3] Ex03에서 배운 Ablation 시각화 패턴\n#   4개 그래프: Val F1, Val Acc, Train Loss, Val Loss\n#   → 과적합 확인: Train Loss ↓ 인데 Val Loss ↑ 이면 과적합\n#   → R-Drop 효과: Exp3이 Exp2보다 train-val gap이 작으면 성공\n# ============================================================\nfig, axes = plt.subplots(2, 2, figsize=(16, 12))\ncolors = ['#e74c3c', '#3498db', '#2ecc71', '#9b59b6']  # 빨/파/초/보\n\n# 좌상: Validation F1 (가장 중요한 지표!)\nfor i, r in enumerate(results):\n    axes[0,0].plot(r['history']['val_f1'], label=r['name'], color=colors[i], marker='o')\naxes[0,0].set_title('Validation F1 Score (Main Metric)')\naxes[0,0].set_xlabel('Epoch')\naxes[0,0].set_ylabel('F1')\naxes[0,0].legend(fontsize=8)\naxes[0,0].grid(True, alpha=0.3)\n\n# 우상: Validation Accuracy\nfor i, r in enumerate(results):\n    axes[0,1].plot(r['history']['val_acc'], label=r['name'], color=colors[i], marker='o')\naxes[0,1].set_title('Validation Accuracy')\naxes[0,1].set_xlabel('Epoch')\naxes[0,1].set_ylabel('Accuracy')\naxes[0,1].legend(fontsize=8)\naxes[0,1].grid(True, alpha=0.3)\n\n# 좌하: Training Loss (과적합 모니터링용)\nfor i, r in enumerate(results):\n    axes[1,0].plot(r['history']['train_loss'], label=r['name'], color=colors[i], marker='o')\naxes[1,0].set_title('Training Loss')\naxes[1,0].set_xlabel('Epoch')\naxes[1,0].set_ylabel('Loss')\naxes[1,0].legend(fontsize=8)\naxes[1,0].grid(True, alpha=0.3)\n\n# 우하: Validation Loss (과적합 = 이게 올라감)\nfor i, r in enumerate(results):\n    axes[1,1].plot(r['history']['val_loss'], label=r['name'], color=colors[i], marker='o')\naxes[1,1].set_title('Validation Loss')\naxes[1,1].set_xlabel('Epoch')\naxes[1,1].set_ylabel('Loss')\naxes[1,1].legend(fontsize=8)\naxes[1,1].grid(True, alpha=0.3)\n\nplt.suptitle('Ablation Study: Learning Curves', fontsize=14, fontweight='bold')\nplt.tight_layout()\nplt.savefig('ablation_learning_curves.png', dpi=150, bbox_inches='tight')\nplt.show()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# STEP 6-3: Confusion Matrix 시각화\n# [Level 3] 4개 실험의 혼동 행렬을 나란히 비교\n#   읽는 법: 대각선 = 정답, 비대각선 = 오분류\n#   주목 포인트: Normal(일반) 행/열의 변화\n#   → Exp1에서 Normal 오분류 많았다면 → Exp3에서 줄었는지 확인\n# ============================================================\nfig, axes = plt.subplots(1, 4, figsize=(24, 5))\n\n# 영문 약자로 표시 (공간 절약)\nshort_names = ['Threat', 'Extort', 'Work', 'Other', 'Normal']\n\nfor i, r in enumerate(results):\n    cm = confusion_matrix(r['val_labels'], r['val_preds'])\n    sns.heatmap(\n        cm, annot=True, fmt='d', cmap='Blues', ax=axes[i],\n        xticklabels=short_names, yticklabels=short_names\n    )\n    axes[i].set_title(f\"{r['name']}\\nF1={r['best_val_f1']:.4f}\", fontsize=10)\n    axes[i].set_ylabel('True')      # 세로 = 실제 라벨\n    axes[i].set_xlabel('Predicted')  # 가로 = 모델 예측\n\nplt.suptitle('Confusion Matrices (Validation Set)', fontsize=14, fontweight='bold')\nplt.tight_layout()\nplt.savefig('ablation_confusion_matrices.png', dpi=150, bbox_inches='tight')\nplt.show()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# STEP 6-4: Best 모델 상세 리포트\n# [Level 3] 클래스별 Precision/Recall/F1 확인\n#   → 어떤 클래스가 약한지 파악 가능\n#   → 발표 시 \"일반 대화 F1이 XX로, 합성데이터가 효과적임을 증명\" 근거\n# ============================================================\nprint(f\"\\nBest 모델: {best_exp['name']}\")\nprint(f\"\\nClassification Report:\")\nprint(classification_report(\n    best_exp['val_labels'], best_exp['val_preds'],\n    target_names=CLASS_NAMES,\n    digits=4\n))"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## STEP 7: Test 예측 & 제출파일 생성\n> Best 모델로 test 500개를 예측하고 `submission_final.csv` 생성"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# STEP 7-1: Best 모델로 Test 예측\n# Ablation에서 가장 F1이 높은 모델의 가중치를 불러와서 예측\n# ============================================================\nprint(f\"Best 모델: {best_exp['name']}\")\nprint(f\"Best Val F1: {best_exp['best_val_f1']:.4f}\")\n\n# Best 모델 가중치 로드\nmodel_final = AutoModelForSequenceClassification.from_pretrained(\n    MODEL_NAME, num_labels=NUM_CLASSES\n).to(DEVICE)\nmodel_final.load_state_dict(best_exp['best_state'])  # Ablation best 가중치\nmodel_final.eval()                                     # 평가 모드 (드롭아웃 OFF)\n\n# Test 데이터셋 (라벨 없음)\ntest_dataset = DKTCDataset(\n    test_df['conversation'].values,\n    labels=None,         # test는 정답 라벨이 없음\n    tokenizer=tokenizer,\n    max_len=MAX_LEN\n)\ntest_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n\n# 예측 실행\nall_preds = []\nwith torch.no_grad():\n    for batch in test_loader:\n        input_ids = batch['input_ids'].to(DEVICE)\n        attention_mask = batch['attention_mask'].to(DEVICE)\n\n        model_kwargs = {'input_ids': input_ids, 'attention_mask': attention_mask}\n        if 'token_type_ids' in batch:\n            model_kwargs['token_type_ids'] = batch['token_type_ids'].to(DEVICE)\n\n        outputs = model_final(**model_kwargs)\n        preds = torch.argmax(outputs.logits, dim=-1)  # 가장 높은 확률의 클래스\n        all_preds.extend(preds.cpu().numpy())\n\nprint(f\"\\n예측 완료: {len(all_preds)}개\")\nprint(f\"\\n예측 분포:\")\npred_counts = Counter(all_preds)\nfor label_idx in sorted(pred_counts.keys()):\n    print(f\"  {IDX2CLASS[label_idx]}: {pred_counts[label_idx]}개\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# STEP 7-2: 제출파일 생성 + 예측 품질 검증\n# submission_final.csv: idx(t_000~) + class(0~4 정수)\n# ============================================================\nsubmission_df['class'] = all_preds\nsubmission_df['class'] = submission_df['class'].astype(int)\n\nsubmission_df.to_csv('submission_final.csv', index=False)\n\nprint(\"submission_final.csv 저장 완료!\")\nprint(f\"\\n미리보기:\")\nprint(submission_df.head(10))\nprint(f\"\\n클래스 분포:\")\nprint(submission_df['class'].value_counts().sort_index())\n\n# ── 품질 검증: 일반대화(4) 비율이 적절한지 체크 ──\n# test 500개 중 일반대화는 ~100개(20%)로 추정\nnormal_count = sum(1 for p in all_preds if p == 4)\nprint(f\"\\n일반 대화 예측: {normal_count}개 ({normal_count/len(all_preds)*100:.1f}%)\")\nif normal_count < 50:\n    print(\"⚠️ 일반대화 예측이 너무 적습니다. 합성데이터 품질을 확인하세요.\")\nelif normal_count > 200:\n    print(\"⚠️ 일반대화 예측이 너무 많습니다. 모델이 과도하게 일반으로 분류하고 있습니다.\")\nelse:\n    print(\"일반 대화 비율이 적절합니다 (test 500개 중 ~100개 추정)\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# STEP 7-3: 예측 샘플 확인 (사람이 눈으로 검증)\n# → 일반대화로 예측된 것이 실제로 일반적인지 확인\n# → 위협으로 예측된 것이 실제로 위협적인지 확인\n# ============================================================\nprint(\"\\n\" + \"=\"*60)\nprint(\"  일반대화(4)로 예측된 test 샘플 확인\")\nprint(\"=\"*60)\nnormal_indices = [i for i, p in enumerate(all_preds) if p == 4]\nfor idx in normal_indices[:10]:  # 최대 10개만 출력\n    text = test_df.iloc[idx]['conversation'][:100]\n    print(f\"  [{test_df.iloc[idx]['idx']}] {text}...\")\n\nprint(f\"\\n위협으로 예측된 샘플도 확인:\")\nfor label_idx in range(4):  # 0~3: 위협 클래스\n    indices = [i for i, p in enumerate(all_preds) if p == label_idx]\n    if indices:\n        i = indices[0]\n        text = test_df.iloc[i]['conversation'][:80]\n        print(f\"  [{IDX2CLASS[label_idx]}] {text}...\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## STEP 8: 프로젝트 정리 & 발표 포인트\n> 최종 요약: 전략별 성과, 논문 근거, 학습 이력 활용을 한눈에 정리"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# STEP 8: 프로젝트 정리 - 발표용 요약\n# ============================================================\nprint(\"\\n\" + \"=\"*60)\nprint(\"  DKTC 프로젝트 최종 정리\")\nprint(\"=\"*60)\n\nprint(f\"\\n[모델] {MODEL_NAME}\")\nprint(f\"[데이터] 원본 {len(train_df)}개 + 합성 일반대화 {len(normal_samples)}개 = {len(train_full)}개\")\nprint(f\"[합성 소스] SmileStyle, KakaoChatData, kor_unsmile, NSMC, 경계케이스\")\n\nprint(f\"\\n[Ablation 결과]\")\nfor r in results:\n    print(f\"  {r['name']}: F1={r['best_val_f1']:.4f}\")\n\nprint(f\"\\n[Best] {best_exp['name']}: F1={best_exp['best_val_f1']:.4f}\")\nprint(f\"[제출] submission_final.csv ({len(all_preds)}개 예측)\")\n\n# ── 발표 포인트 ──\nprint(f\"\\n{'='*60}\")\nprint(\"  발표 포인트 (가브리엘 페터슨 탑다운 학습법)\")\nprint(f\"{'='*60}\")\nprint(f\"\\n  [Level 1] 문제 발견: train에 일반대화 0개 → EDA에서 즉시 발견\")\nprint(f\"  [Level 2] 최신 기법 적용:\")\nprint(f\"    - KcELECTRA: Clark et al. (2020) - 한국어 구어체에 최적화된 사전학습\")\nprint(f\"    - Focal Loss: Lin et al. (2017) - 클래스 불균형 해결\")\nprint(f\"    - R-Drop: Liang et al. (2021) - 소규모 데이터 과적합 방지\")\nprint(f\"    - 합성데이터 5개 소스: AugGPT (Dai et al., 2023) 영감\")\nprint(f\"  [Level 3] Ablation으로 정량 증명: 각 기법의 F1 기여도를 숫자로 보여줌\")\n\nprint(f\"\\n  [학습 이력 활용]\")\nprint(f\"    - Ex03: Ablation Study 설계 방법론 → STEP 5 실험 설계\")\nprint(f\"    - Ex06: 텍스트 전처리, Dataset 구조 → STEP 3, 4\")\nprint(f\"    - Ex07: 한국어 토큰화 이해 → STEP 3 토큰 분석\")\nprint(f\"    - Ex09: Transformer Fine-tuning → STEP 4 모델 구성\")\n\nprint(f\"\\n  [핵심 차별화]\")\nprint(f\"    1. 경계 케이스 25개 - '죽을래 ㅋㅋ' 같은 농담을 일반대화로 학습\")\nprint(f\"    2. 5개 소스 통합 - 단일 소스가 아닌 다양한 구어체 데이터\")\nprint(f\"    3. Ablation으로 정량 증명 - 각 기법의 기여도를 숫자로 보여줌\")\n\nprint(f\"\\n✅ 완료!\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Colab에서 제출파일 다운로드\nfrom google.colab import files\nfiles.download('submission_final.csv')"
  }
 ]
}